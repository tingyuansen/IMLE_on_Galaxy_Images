{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# import packages\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear, LeakyReLU, MSELoss, Sequential\n",
    "from torch.optim import Adam\n",
    "\n",
    "from kymatio import Scattering1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define plot properties\n",
    "from cycler import cycler\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import rc\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def rgb(r,g,b):\n",
    "    return (float(r)/256.,float(g)/256.,float(b)/256.)\n",
    "\n",
    "cb2 = [rgb(31,120,180), rgb(255,127,0), rgb(51,160,44), rgb(227,26,28), \\\n",
    "       rgb(166,206,227), rgb(253,191,111), rgb(178,223,138), rgb(251,154,153)]\n",
    "\n",
    "rcParams['figure.figsize'] = (9,7.5)\n",
    "#rcParams['figure.dpi'] = 300\n",
    "\n",
    "rcParams['lines.linewidth'] = 1\n",
    "\n",
    "rcParams['axes.prop_cycle'] = cycler('color', cb2)\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['axes.grid'] = False\n",
    "\n",
    "rcParams['patch.facecolor'] = cb2[0]\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "\n",
    "rcParams['font.size'] = 23\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Calculate scattering coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from kymatio import Scattering1D\n",
    "import kymatio\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch\n",
    "import torch.utils.data as utils\n",
    "\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#=========================================================================================================\n",
    "# load light curves\n",
    "real_spec = np.load(\"../light_curve.npy\")[:10,:]\n",
    "print(real_spec.shape)\n",
    "\n",
    "### change the amplitude\n",
    "#real_spec = real_spec*2.\n",
    "\n",
    "## mix two modes\n",
    "#real_spec = (real_spec[:,:] + real_spec[::-1,:])/2.\n",
    "\n",
    "\n",
    "#================================================================================================\n",
    "# define wavelet scattering hyperparameters\n",
    "J = 6\n",
    "Q = 8\n",
    "T = real_spec.shape[1]\n",
    "\n",
    "# convert into torch variable\n",
    "x = torch.from_numpy(real_spec[:,:T]).type(torch.FloatTensor)\n",
    "print(x.shape)\n",
    "\n",
    "# define wavelet scattering\n",
    "scattering = Scattering1D(J, T, Q)\n",
    "\n",
    "#================================================================================================\n",
    "# perform wavelet scattering\n",
    "Sx_all = scattering.forward(x)\n",
    "\n",
    "# calculate invariate representation\n",
    "Sx_all = torch.mean(Sx_all, dim=-1)\n",
    "\n",
    "# normalize wrt to the first coefficient\n",
    "for i in range(Sx_all.shape[0]):\n",
    "    Sx_all[i,:] = Sx_all[i,:]/np.abs(Sx_all[i,0])\n",
    "    \n",
    "# take log to normalize the coefficient better\n",
    "Sx_all = torch.log10(Sx_all[:,1:])\n",
    "print(Sx_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx_all_1 = np.copy(Sx_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx_all = Sx_all.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Sx_all_1[0,:])\n",
    "plt.plot(Sx_all_1[0,:])\n",
    "plt.plot(Sx_all[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check wavelet scattering coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scattering coefficients\n",
    "Sx = np.load(\"../Sx_all.npy\")\n",
    "plt.hist(Sx.ravel(), bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Visualize first order WST coefficients as a proxy for power spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RealNVP(\n",
       "  (t): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (s): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=50, out_features=7, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    "#=======================================================================================================\n",
    "# In [2]:\n",
    "# define normalizing flow\n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, nets, nett, mask, prior):\n",
    "        super(RealNVP, self).__init__()\n",
    "\n",
    "        self.prior = prior\n",
    "        self.mask = nn.Parameter(mask, requires_grad=False)\n",
    "        self.t = torch.nn.ModuleList([nett() for _ in range(len(masks))])\n",
    "        self.s = torch.nn.ModuleList([nets() for _ in range(len(masks))])\n",
    "\n",
    "    def g(self, z):\n",
    "        x = z\n",
    "        for i in range(len(self.t)):\n",
    "            x_ = x*self.mask[i]\n",
    "            s = self.s[i](x_)*(1 - self.mask[i])\n",
    "            t = self.t[i](x_)*(1 - self.mask[i])\n",
    "            x = x_ + (1 - self.mask[i]) * (x * torch.exp(s) + t)\n",
    "        return x\n",
    "\n",
    "    def f(self, x):\n",
    "        log_det_J, z = x.new_zeros(x.shape[0]), x\n",
    "        for i in reversed(range(len(self.t))):\n",
    "            z_ = self.mask[i] * z\n",
    "            s = self.s[i](z_) * (1-self.mask[i])\n",
    "            t = self.t[i](z_) * (1-self.mask[i])\n",
    "            z = (1 - self.mask[i]) * (z - t) * torch.exp(-s) + z_\n",
    "            log_det_J -= s.sum(dim=1)\n",
    "        return z, log_det_J\n",
    "\n",
    "    def log_prob(self,x):\n",
    "        z, logp = self.f(x)\n",
    "        return self.prior.log_prob(z) + logp\n",
    "\n",
    "    def sample(self, z):\n",
    "        x = self.g(z)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "#==================================================================================\n",
    "# restore models\n",
    "flow = torch.load(\"../flow_final_dense.pt\", map_location=lambda storage, loc: storage) # load in cpu\n",
    "flow.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx_coefficient = np.load(\"../Sx_all_mixed_dense.npy\").T\n",
    "plt.plot(np.log10(Sx_coefficient), color=cb2[0], alpha=0.1);\n",
    "plt.plot(np.log10(Sx_coefficient[:,0]), color=cb2[0], label=\"mixed\");\n",
    "\n",
    "Sx_coefficient = np.load(\"../Sx_all_normal_dense.npy\").T\n",
    "plt.plot(np.log10(Sx_coefficient), color=cb2[1], alpha=0.1);\n",
    "plt.plot(np.log10(Sx_coefficient[:,0]), color=cb2[1], label=\"normal\");\n",
    "\n",
    "# flow_sample = flow.sample(torch.from_numpy(np.random.normal(size=(1000,7))).float()).detach().numpy().T\n",
    "# plt.plot(flow_sample, color=cb2[2], alpha=0.1);\n",
    "# plt.plot(flow_sample[:,0], color=cb2[2], label=\"sample\");\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Coefficients\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yting/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log10\n",
      "  \"\"\"\n",
      "/Users/yting/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log10\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  0.,   1.,   3.,   1.,   2.,   6.,   3.,   6.,   3.,   7.,   6.,\n",
       "         11.,  12.,  17.,  11.,  18.,  21.,  20.,  38.,  47.,  47.,  50.,\n",
       "         55.,  68.,  53.,  60.,  70., 102.,  81.,  63.,  48.,  40.,  11.,\n",
       "         12.,   4.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.]),\n",
       " array([-6.  , -5.92, -5.84, -5.76, -5.68, -5.6 , -5.52, -5.44, -5.36,\n",
       "        -5.28, -5.2 , -5.12, -5.04, -4.96, -4.88, -4.8 , -4.72, -4.64,\n",
       "        -4.56, -4.48, -4.4 , -4.32, -4.24, -4.16, -4.08, -4.  , -3.92,\n",
       "        -3.84, -3.76, -3.68, -3.6 , -3.52, -3.44, -3.36, -3.28, -3.2 ,\n",
       "        -3.12, -3.04, -2.96, -2.88, -2.8 , -2.72, -2.64, -2.56, -2.48,\n",
       "        -2.4 , -2.32, -2.24, -2.16, -2.08, -2.  ], dtype=float32),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHECAYAAADFxguEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dfbRdVXnv8e8jIYRUgRCCiCEEooAtAoFIhVakAnqlVayv+Er10gSxeu3FN2zFVFG4lErrtdRkoLVcdaAXK2JFb0GgVIWmYIyCiiUhYKQIgRDFEALy3D/W2mT3cM7e+yT7dZ7vZ4wz5l57zbn2c9gj5Je55lorMhNJkqRSPGnQBUiSJHWT4UaSJBXFcCNJkopiuJEkSUUx3EiSpKIYbiRJUlGmDbqAftljjz1y/vz5gy5DkiR1wU033bQ+M+eMt2/KhJv58+dz4403DroMSZLUBRFxx0T7PC0lSZKKYriRJElFMdxIkqSiGG4kSVJRDDeSJKkohhtJklQUw40kSSqK4UaSJBXFcCNJkopiuJEkSUUx3EiSpKIYbiRJUlEMN5IkqSiGG0mSVBTDjSRJKorhRpIkFcVwI0mSitJxuImIvSLiDRHxNxHx7YjYFBEZEd/rYOy0iHhnRHw3Ih6MiAfqY5zSwdh9I2J5RNwZEQ9HxF0R8bmIOLjT2iVJ0tQxbRJ9TwYumOwHRMROwDeAY4HHgFuA6cDRwNERcRxwSmbmOGOfA1wF7AJsBH4A7Au8DnhFRLw8M6+YbE2S1M6ylRd21G/JwtN7XImkyZrMaalfUAWNc4FXAu/vcNw5VMHmTuDQzDwkMw8Cnk8VWN4InDZ2UETsDPwjVbD5LLB3Zi4C9gbOA3YCLomIp07id5AkSYXrONxk5qcz84TMPDMzvwT8Z7sxETEHeFu9eWpm3tx0vOuA99SbZ0XEDmOG/zEwF7i9HrupHvcI8D7gO8BTgHd1+jtIkqTy9XpB8UlUp6BWZ+aV4+y/GNgE7EU1k9Ps1XX76cx8uHlHfQpr2Zh+kiRJPQ83R9XtdePtzMzNwIoxfalncRa1Ggv8S93Oi4inb2edkiSpEL0ONwfU7W0t+qyu2wOb3ptPtaam1difAlvGGStJkqawXoeb3ev2/hZ9GvtmjTNuwrGZ+RjVguSxYyVJ0hTW63Azo263tOizuW53Hmfctox9XEQsjogbI+LGe++9t2WhkiSpDL0ON43wMb1Fn0aQeWiccdsy9nGZuTwzF2Xmojlz5rQsVJIklaHX4WZD3c5u0adxCmpD03vNr8cdGxFPAnYdp78kSZrCeh1ubq3bZ7Tos2BMX6jubdM4HTXR2H3YOqtz6wR9JEnSFNPrcHN93T5vvJ0RMQM4ckxfMvPXwL/Xm8dMcOzGfXF+mpk/2846JUlSIXodbi6nmoFZEBEnjLP/TcBM4Oc88X42l9btm+vnUz0uIgJYUm9+sXvlSpKkUdfTcJOZ9wCNp89d1Pwk74g4huoZUQAfzsxHxwxfDtwF7FePnVmP25Hq+VZHAw8C5/fuN5AkSaOm46eCR8Q+wMqmtxqzKQdHxPqm98/LzPOats8EDqc6vbQqIhpPBW/ceO/zbA1Aj8vMTRHxcuBK4A3ASyLiNqqngu9BNSP0usy8u9PfQZIklW8yMzc7UF251Ph58gTvz2weVD9i4TjgDOD7VAuI96ZaY/OWzHx9/ayoJ8jMfwMOAT4F/BJ4NvAocAmwKDO/Oon6JUnSFNDxzE1mrgViWz6kPuX0sfpnsmPXAqduy+dKkqSpp9cLiiVJkvrKcCNJkopiuJEkSUUx3EiSpKIYbiRJUlEMN5IkqSiGG0mSVBTDjSRJKorhRpIkFcVwI0mSimK4kSRJRTHcSJKkohhuJElSUQw3kiSpKIYbSZJUFMONJEkqiuFGkiQVxXAjSZKKYriRJElFMdxIkqSiGG4kSVJRDDeSJKkohhtJklQUw40kSSqK4UaSJBXFcCNJkopiuJEkSUUx3EiSpKIYbiRJUlEMN5IkqSiGG0mSVBTDjSRJKorhRpIkFcVwI0mSimK4kSRJRTHcSJKkohhuJElSUQw3kiSpKIYbSZJUFMONJEkqiuFGkiQVxXAjSZKKYriRJElFMdxIkqSiGG4kSVJRDDeSJKkohhtJklQUw40kSSqK4UaSJBXFcCNJkopiuJEkSUUx3EiSpKIYbiRJUlEMN5IkqSiGG0mSVBTDjSRJKorhRpIkFcVwI0mSitKXcBMRu0TEByPiuxHxy4jYEhF3RcSXI+L4FuOmRcQ763EPRsQDEfHtiDilH3VLkqTRM63XHxARc4HrgP2Ax4C1wEZgAfAy4GUR8ReZuXTMuJ2AbwDH1uNuAaYDRwNHR8RxwCmZmb3+HSRJ0ujox8zNx6iCzX8Ah2Tmgsw8HJgDnF33OSsiDh8z7hyqYHMncGhmHpKZBwHPpwpHbwRO60P9kiRphPQj3PxB3b47M29pvJmZWzLzA8AqIIATG/siYg7wtnrz1My8uWncdcB76s2zImKHXhYvSZJGS09PS0XENKpTSQCrJ+h2G3AosGPTeyfV41Zn5pXjjLkYuADYi2om5+quFCxJk7Rs5YVt+yxZeHofKpHU0NOZm8x8FPhBvXn02P31uppF9eYNTbuOqtvrJjjuZmDFmL6SJEl9OS31fuBR4C8j4o8jYq+ImBkRRwBfBvYFLsvMrzeNOaBub2tx3MZM0IFdr1iSJI2snl8tlZlfj4gXAmcBy8fsXg+8Axg7r7t73d7f4tCNfbO2u0hJklSMft3E75nA06gu6b6DahHxg8AewH8HjhzTf0bdbmlxzM11u/NEHSJicUTcGBE33nvvvdtStyRJGjE9DzcR8VfAMqow8+zMnJ+Zh1HNzryHajHx1WMuBW8El+lMrBGAHpqoQ2Yuz8xFmblozpw52/w7SJKk0dHTcBMRBwPvpFpz86rM/GFjX2Y+kpl/Cfw9VVA5u2nohrqd3eLwjVNXG1r0kSRJU0yvZ26eV3/GTzLz9gn6fKNum09N3Vq3z2hx7AVj+kqSJPU83OzSQZ+o2xlN711ft88bd0DEDLaGoevH6yNJkqamXoebn9TtARGx3wR9/lvdNs/AXE61mHhBRJwwzpg3ATOBnzPBvXAkSdLU1Otw8/+oAsg04P9GxLMaOyJix4h4N/BH9Vv/0NiXmfew9fLwi+q1O41xxwDn1Zsfrm8UKEmSBPT4PjeZuSkiXgd8BTgCuDki7gQeoFoz85S66z8Cfztm+JnA4cAxwKqIaDwVvHHTvs/zxPvjSJKkKa7nl4Jn5tXAwcBfAz8C9qy3H6JaTPzazHxFZv56zLjNwHHAGcD3qcLQ3lRrbN6Sma/PzOx1/ZIkabT0/A7FAJl5B/Cn2zDuUeBj9Y8kSVJb/bpDsSRJUl8YbiRJUlEMN5IkqSiGG0mSVBTDjSRJKorhRpIkFcVwI0mSimK4kSRJRTHcSJKkohhuJElSUQw3kiSpKIYbSZJUFMONJEkqiuFGkiQVxXAjSZKKYriRJElFMdxIkqSiTBt0AZLUb3nN0vaddtuz53VI6g1nbiRJUlEMN5IkqSiGG0mSVBTX3EjSdrhhzfq2fZYs7EMhkh7nzI0kSSqK4UaSJBXFcCNJkopiuJEkSUUx3EiSpKIYbiRJUlG8FFzSlLP8gR+279RJHwAO3q5aJHWfMzeSJKkohhtJklQUw40kSSqK4UaSJBXFcCNJkopiuJEkSUUx3EiSpKJ4nxtJQ2HZygvb9lmy8PQ+VCJp1DlzI0mSimK4kSRJRTHcSJKkohhuJElSUQw3kiSpKIYbSZJUFMONJEkqiuFGkiQVxXAjSZKKYriRJElFMdxIkqSiGG4kSVJRDDeSJKkohhtJklQUw40kSSqK4UaSJBXFcCNJkopiuJEkSUWZNugCJKl0y1Ze2LbPkoWn96ESaWpw5kaSJBXFcCNJkorS13ATES+NiMsi4q6IeDgi7o6Ib0fE2RHxhFNkETEtIt4ZEd+NiAcj4oG6/yn9rFuSJI2Ovqy5iYjpwOeAV9Zv/RRYBcwGFgFHA+cCDzaN2Qn4BnAs8BhwCzC97nt0RBwHnJKZ2Y/fQZIkjYZ+zdz8A1Ww+Xfg8Mycl5lHZuYCYBZwEvDwmDHnUAWbO4FDM/OQzDwIeD6wEXgjcFqf6pckSSOi5+EmIk4CTgZuB47LzJXN+zNzU2ZenpmPNI2ZA7yt3jw1M29u6n8d8J5686yI2KGnv4AkSRop/Zi5OaNuP5qZv+xwzElUp6BWZ+aV4+y/GNgE7EU1kyNJkgT0eM1NRMwGnldvXh4RRwGnAAuowsmNwKcy864xQ4+q2+vGO25mbo6IFVSnrY4Cru5y6ZKmuHUbNnXWcdfe1iFp8no9c7Oobu8B3gp8G1gCHA+8FPgQ8B8R8fIx4w6o29taHHt13R7YnVIlSVIJeh1unla3s4ClwDXAYcBOVKHkUmAm8PmIeHbTuN3r9v4Wx27sm9WtYiVJ0ujr9aXgT67bHYGfAb+fmZvr934SEa8BbqIKPB8AXl3vm1G3W1ocu3GcnSfqEBGLgcUA8+bNm3TxkkZPJ486kFS2Xs/cbG56/bdNwQaAzHwMuKDefFFEPGnMuOktjt0IQA9N1CEzl2fmosxcNGfOnEmULUmSRlWvw82Gptc/mqBP4/1d2Ho6qjFudotjj+0rSZLU83Dz46bXY2/S19A8m9O4Z82tdfuMFsdeMKavJElSX8LNffXr/Sfo0wgpm5v6Xl+3z3tid4iIGcCRY/pKkiT1Ntxk5q+BL9Wbb56g21vq9trMfLR+fTnVYuIFEXHCOGPeRHWV1c+Z4F44kiRpaurHHYo/SrXo94iIODcidgSIyjuBlwBJ9SwpADLzHqBxycNFEXFwY19EHAOcV29+uCkQSZIk9f6p4Jl5R0S8DvgC8F7gjyPiNmAe1eMTEjijfmZUszOBw4FjgFUR0XgqeOOmfZ9nawCSJEkC+vRU8My8jCqofJZqbc1CqsXDlwHPz8wLxhmzGTiO6tlU36dam7M31Rqbt2Tm6zMz+1G/JEkaHT2fuWnIzFuAN05yzKPAx+ofSZKktvoycyNJktQvhhtJklSUvp2WkqQSzd24om2fG9Yc2bbPkoXdqEYSOHMjSZIKY7iRJElFMdxIkqSiGG4kSVJRDDeSJKkohhtJklQULwWX1HPLVrZ/DNwNa9a37dPR5dJrr+2gk6SSOXMjSZKKYriRJElFMdxIkqSiGG4kSVJRDDeSJKkohhtJklQUw40kSSqK97mRNDI6uV+OJDlzI0mSimK4kSRJRTHcSJKkohhuJElSUQw3kiSpKIYbSZJUFMONJEkqiuFGkiQVxXAjSZKKYriRJElF8fELkrZLJ49EuGHN+j5UIkkVZ24kSVJRDDeSJKkohhtJklQU19xI2j5rr+2g08G9rkKSHufMjSRJKorhRpIkFcVwI0mSiuKaG0k9N3fjirZ91u16ZB8qqT9rw6a+fVanOrlf0JKFp/ehEmn0OXMjSZKKYriRJElFMdxIkqSiuOZGmoI6Wd8hSaPKmRtJklQUw40kSSqK4UaSJBXFNTeSijKM97DpxA1r1rfts2RhHwqRCuDMjSRJKorhRpIkFcXTUlJh8pql7TvttmdnB1t77faUIkkD4cyNJEkqiuFGkiQVxXAjSZKK4pobSdtlVC+9llQuZ24kSVJRDDeSJKkohhtJklQUw40kSSqK4UaSJBXFcCNJkopiuJEkSUUZyH1uIuJE4Gv15qrMPGyCfjOBdwOvBvYDHgK+C3w8M7/aj1ol9cfcjSs66HViz+uQNPr6PnMTEU8BPtlBv92BFcBS4JnArcAvgOOByyPiwz0sU5IkjahBnJb6X8A+wGVt+l0E/BawCliQmQszcz/gVcAjwJ9HxIt7WqkkSRo5fQ03EfG7wGnAl4GvtOh3KPCHwGPAyZn508a+zLwUOL/e/FDvqpUkSaOob2tuImIG1WzMg8DbgRNadH9V3V6TmT8eZ/8ngTOBRRGxf2au6Wqx0gi7Yc369p0O37P3hUjSgPRz5uYs4EDg/Zn5szZ9j6rb68bbmZl3AmvH9JUkSepPuImIw6iueloBXNjBkAPq9rYWfVbX7YHbUZokSSpMz8NNROwAfKreXJyZj3UwbPe6vb9Fn8a+WdtamyRJKk8/1ty8CzgcOC8zV3U4ZkbdbmnRZ3Pd7jxRh4hYDCwGmDdvXocfLWlorb120BUM1LKV7Se+lyw8vQ+VSMOtpzM3EfFMqvvU3A78xSSGNoLL9BZ9GgHooYk6ZObyzFyUmYvmzJkziY+XJEmjqtenpT5JFULempmbJjFuQ93ObtGncepqQ4s+kiRpiun1aakjgAT+ISLG7mucTvqtiLi7fv3yzPwO1d2Inw48o8WxF9TtrV2qVZIkFaAfa24CeGqbGhr7G6ehrgdeABwz7gEj5gHz680btr9ESZJUip6elsrM3TIzxvsB3lx3W9X0/rX1e5fW7bERcdA4hz6tbm/KzNXj7JckSVPUIJ4t1VZmfo/q2VNPAi6JiH0a+yLilVRXYEG1WFmSJOlxfXv8wjY4leoGfYcCqyPiFmA3tp6OOicz/2lAtUlD64pY27bPXH6z94VI0oAM5cwNQGbeBzyH6uGYq4GDqMLN1cBJmfn+AZYnSZKG1MBmbjLzM8Bn2vT5FfDB+keSJKmtoZ25kSRJ2hbDvOZGUq+M6GMM1m2YzL1AJU1VztxIkqSiGG4kSVJRDDeSJKkorrmRpqBO167MnTWzx5VIUvc5cyNJkopiuJEkSUUx3EiSpKK45kYaEnnN0rZ94vfa95Gkqc6ZG0mSVBTDjSRJKoqnpSRpRNywZn3bPksW9qEQacg5cyNJkopiuJEkSUUx3EiSpKK45kYaIZ1cLq7hM3fjirZ91u16ZB8qkaYGZ24kSVJRDDeSJKkohhtJklQU19xImtC6DZsGXYIkTZozN5IkqSiGG0mSVBTDjSRJKoprbqQ+6Nb9aTp5thDRlY+SpJHlzI0kSSqK4UaSJBXFcCNJkopiuJEkSUUx3EiSpKIYbiRJUlEMN5IkqSiGG0mSVBTDjSRJKorhRpIkFcVwI0mSimK4kSRJRTHcSJKkohhuJElSUQw3kiSpKIYbSZJUFMONJEkqiuFGkiQVZdqgC5BGXV6zdNAlSJKaOHMjSZKKYriRJElFMdxIkqSiGG4kSVJRDDeSJKkohhtJklQULwWX+uCGNevb9nnu/nv0oRJJKp8zN5IkqSiGG0mSVBTDjSRJKorhRpIkFcVwI0mSimK4kSRJRTHcSJKkovQ83ETl6Ig4NyK+FRH3RcQjEXFvRPxzRLw+IqLF+JkR8cGIuCUiNtXjr4yIl/S6dkmSNHr6cRO/FwBXNW2vAW4H9gNOqH9eGxGvyMyHmwdGxO7AdcBvAY8AtwC7AccDx0fE2Zn5gd7/CpIkaVT047RUUIWZ/wE8NTMXZOaizJwNvAl4GPh94EPjjL2IKtisAhZk5sLM3A94FVXY+fOIeHEffgdJkjQi+hFuVgAHZubHM/Oe5h2Z+X/YGmpOjYjH64mIQ4E/BB4DTs7MnzaNuxQ4v94cLxRJkqQpquenpTLzF226fB34CLA7MAf4ef3+q+r2msz88TjjPgmcCSyKiP0zc0036tXUkNcs7ahf/F5n/bph+QM/bNvnEPbsQyWSNNqG4WqpnZteP9T0+qi6vW68QZl5J7B2TF9JkjTFDUO4eW3drhozy3NA3d7WYuzquj2w61VJkqSRNNBwExFHAKfVm+eO2b173d7f4hCNfbO6WZckSRpd/bgUfFwR8VTgH+savpyZl4zpMqNut7Q4zOa63Xm8nRGxGFgMMG/evG0vVuqDdRs2te8Ta3tfiCSNuIHM3ETErlQLiecBNwF/NE63RnCZ3uJQjQD00Hg7M3N5fdn5ojlz5mxjtZIkaZT0PdxExJOBbwALqW7K96IJrqjaULezWxyucepqQ4s+kiRpCulruImImcDXgOcCPwGOz8z7Juh+a90+o8UhF4zpK0mSpri+hZuImAF8BTiG6hLu4zLz7hZDrq/bYyY43jxgfr15Q3eqlCRJo64v4SYidgS+RPVMqHXACzJzXZthl9btsRFx0Dj7G1dZ3ZSZq8fZL0mSpqB+PBV8B+BzwInA3VTB5vZ24zLze8BlVDVeEhH7NB3zlcC76s2l3a5ZkiSNrn5cCv5qtj5KYTPw9xExUd+3Z+bKpu1TqW7QdyiwOiIaTwWfX+8/JzP/qesVS112hZdwS1Lf9CPc7NT0ej5bg8l4dm3eyMz7IuI5wHuoQtJBVAHpauBvMvPyrlYqSZJGXj8enPkZ4DPbMf5XwAfrH0mSpJaG4dlSkiRJXTOwxy9Io2DZygvb9jlkzfr2B5pwmZkkqducuZEkSUUx3EiSpKIYbiRJUlEMN5IkqSiGG0mSVBTDjSRJKorhRpIkFcX73EitrL22g0579roKSdIkOHMjSZKKYriRJElFMdxIkqSiuOZGkobA3I0r2vZZt+uRfahEGn3O3EiSpKIYbiRJUlE8LaXiXHDVrW37vHOHPhQiSRoIZ24kSVJRDDeSJKkohhtJklQU19xoSjrr9hs76jd31sweVyJ1VydrzmbO/mbbPksWnt6NcqSBcOZGkiQVxXAjSZKKYriRJElFcc2NinP/nWf09fOuiLV9/Typle9v/ELbPs+dvUcfKpEGx5kbSZJUFMONJEkqiuFGkiQVxTU3Gil5zdJBlyBJGnLO3EiSpKIYbiRJUlEMN5IkqSiGG0mSVBTDjSRJKorhRpIkFcVwI0mSimK4kSRJRTHcSJKkohhuJElSUXz8gobGsi+/um2fxbv9Zh8qkSSNMmduJElSUQw3kiSpKIYbSZJUFNfcTGHLVl7Yts+Shaf37TidWP7AD7tyHGkUzd24om2fdbse2bbPDWvWt+2zZGFHJUlDyZkbSZJUFMONJEkqiuFGkiQVxTU3U9i6lVe079TBWpl+nr9ft2FTdw4kSSqWMzeSJKkohhtJklQUw40kSSqKa25GTF6ztG2fv/71a/v6eSVnZNf4aKrq5/2rpG4r928lSZI0JRluJElSUTwt1ScXXHVr2z4zZ3+zbZ/F3ShmEjp73MHBbXt84NN/0LbP3FkzO/gsSZJac+ZGkiQVxXAjSZKKYriRJElFGYk1NxHxPOBdwFHALsA64CvARzLz/kHWBp1dLv3cO9o/omD5xj3b9jnkgfbHuT/OaNunU51cCj2XFX37LEn90c/HqkjdNvQzNxHxVuBa4KXAI8AtwN7A/wRWRcS+g6tOkiQNm6EONxGxEPjfVHW+HZibmUcAc4Fv1u0XBlehJEkaNkMdboAPADsAn8/MT2RmAtSnok4Gfgn8dkT8/gBrlCRJQ2Ro19xExJOBF9ebfzd2f2auj4hLgTcDrwG+1sfyJu2KWNtBr/Zrbjo7jiT1XiePaIDOHtPQyb3A/vT4Azv6PGmYZ24WAjOALcC/TdDnX+r2qL5UJEmSht4wh5sD6vaOzHxkgj6r63b/iNixDzVJkqQhN8zhZve6bXWpd2Pfk6guEZckSVNc1Gt0h05EfAD4EPCvmXnMBH32Z+vszT6ZuW7M/sVsfRzTgUD7k7rbZg+g/U0hNOz8Hsvg91gGv8cy9PJ73Dcz54y3Y2gXFAOb63Z6iz4zml4/NHZnZi4HlnezqPFExI2ZuajXn6Pe8nssg99jGfweyzCo73GYT0ttqNvZLfo0Tl09Bvyit+VIkqRRMMzhpnEKaV6LxcIL6nZNi0XHkiRpChnmcLMSeJjqtNRzJ+jz/Lq9vi8VTaznp77UF36PZfB7LIPfYxkG8j0O7YJigIi4DDiJ6g7Frx+zbw9gDfAU4CWZ+U8DKFGSJA2ZYZ65gepqqceA10XEn0REAETE7sAlVMHm3xnyuxNLkqT+GeqZG4CI+BPg40AAdwF3A88Cdq63fzczbx9chZIkaZgM+8wNmfkJ4Fjgq8BOwMHAfwJ/DRwyzMEmIg6NiIsiYk1EbI6I+yNiVUR8IiL2HXR9ai0ijo2IbPNzyaDr1ORFxN4R8UDT97jboGtSaxFxWEScGxHfjIjbI+LB+v+rt0fEZyNiorWZGiIR8cyIeG9EfD0ifhYRWyJiY0SsiIj31c+V3P7PGfaZm1EVEe8BPkr1VPP7gduBmcA+wJNxndDQi4hjgWuoFrbfOEG3qzJzab9qUnc0redrmJWZDwyqHrUXEUuBD1ItVbiHauZ+JjCf6p5nCfxZZp4zoBLVRkTsADza9NbdwDpgL2Bu/d5q4LjMvGO7Pstw030RsQT4JNUfwMXAVzPzsXrfk6ge9PmzzFw7sCLVVlO4uSMz5w+2GnVLRLwa+AJwGfCy+m3DzZCLiOOAWcDVmXl/0/u7AWcDb6MKOEdl5kQPW9YARcQ04D6qvx//PjN/3LTvucDngf2Af8vM7ZqJM9x0WUQ8neoePdOB387MlQMuSdvIcFOe+mKEHwJbgBOBH9S7DDcjrL7Y5GbgN4HzMvO9Ay5J46i/p1nN4XTM/qOBb9ebCzPze9v6WUO/5mYELQF+A/iiwUYaOhcAT6X6V/6DA65FXZLVv9IbswAzB1mLJpaVCR+GnZnfATbWmwduz2cN87OlRlVjmvsrETGf6rTUwvq9HwGfy8ybBlCXtt0uEbGM6o7YW6jOCV+emVcOtixNRkS8EHgT8KXM/Gr951MFiIgZwBH15kTr4zTk6tNWjScSbNquY3laqnsiYibwS6oZsXcBS6kWDzdLqmnT9/W3Ok1W02mpiXwTODkzfXLxkIuI36A6bbE78KzMvKsON42rLT0tNYIiYleqK2iXAscD3wGen5mPthqn4RQRrwAupVp0/LTt+X+rp6W6a0+2/jc9h+ox7ydS3ZNnL+Cset97I2Jx/8vTJD0EXAy8iOoqt52orsx4F/Ar4Djg8voKAA23j1J9d2dm5l0DrkXbISLmNi7hBx4AvgUcDvwZ1VU2BpsRVAfV8+vNT23vPxqduemiiDiYrQsUk2pB1Koxff4GeAfVvXr2ycxf97dKdUNEHAX8K9Wl/m/MzM8OuCRNoP6uvgWsAH6n6crF+ThzM3IiYg7w5XpzDrAv1T88VgHvyMzrBlWbtk39D9UiKVQAAANCSURBVMTLqSYD1gKHZebGloPacOamFhFnd3DDtvF+1jYdZnPT6yvHBpvaX9Xt04DDevX7TGVd+i5byszrqaZPAV7ek19kiuvG9xgR04GLqO6NsrgRbNQ/3f7zmJn3Zubv1j8HAnsAf051euqqOsyqy3r1/9X6CqrlVMFmA9U94LYr2IALipv9iur6+8lqXvm9oen1j8brnJl3RsSvqK6o2g9wcXH3deO77MR3gNcAz9yGz1J73fge30t1efC5mfmDCfqrt3r65zEzHwQ+Uq95fD/VMwlP2IbPU2u9+h4/DryFar3qizLz5m34jCfwtFSXRcQ9VFOlE95rISLuo1rYeHJmfqGf9al7IuI04O+AH2fmswZdj56o6U7E9/Ff74wK1SnFPerX91CdSj4/M89HI6e+Cdz1wIbM3H3Q9ai9iDgfOIPqyqgXZea3unVsZ2667ztU/zPdf7yd9d00G3/w1vWrKPXEwXXr9zj8ZrfZv2fdduW5NhqIxt9nLvAfARFxNlWw2Qy8tJvBBlxz0wuNmZgTI2Kvcfa/pW434v0YRlZE7A28od7850HWooll5ssyM8b7oTot3DCrfn/pgErV9ntl3Xrz1CEXEe+nurptC/CKzPxmtz/DcNN9X6S6YmomcHFENKa9G/dNaVwOfn5mPtz/8tSpiPhiRLywvrFU8/tHAlcBu1I9vG/ZIOqTppKIuDgifieq5/M1v79bRPwF1VWoUN2FWkMqIt4BfITqNPHJmXlFTz7HNTfdFxHPAP4F2JvqidI3A7uwdeHpl4DXeBn4cIuIB6gCzENUdyX+FdV3uk/dZR3wBxNcFach56Xgo6W+rw1U6zMafx53pfr/6jSqvyzPdM3U8KpnvNcBQXUBzg9bdP90Zn56Wz/LNTc9kJm3RcSzgfdRPY7hYKqQ8y2qy1IvTlPlKHgfcAzVJft7UwXUB6nWVV0OLPMvRKlv3gj8HvAcqltp7EYVdG6h+sfkssxs9ZelBm86VbCB6gnvv9Oi71Xb80HO3EiSpKK45kaSJBXFcCNJkopiuJEkSUUx3EiSpKIYbiRJUlEMN5IkqSiGG0mSVBTDjSRJKorhRpIkFcVwI0mSimK4kSRJRfn/cl1u6sotOLYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choose a index\n",
    "ind = 6\n",
    "\n",
    "y_tr = np.load(\"../Sx_all_normal_dense.npy\")\n",
    "y_tr = np.log10(y_tr)\n",
    "plt.hist(y_tr[:,ind], bins=50, range=[-6,-2], alpha=0.5);\n",
    "\n",
    "y_tr = np.load(\"../Sx_all_mixed_dense.npy\")\n",
    "y_tr = np.log10(y_tr)\n",
    "plt.hist(y_tr[:,ind], bins=50, range=[-6,-2], alpha=0.5);\n",
    "\n",
    "flow_sample = flow.sample(torch.from_numpy(np.random.normal(size=(1000,7))).float()).detach().numpy()\n",
    "plt.hist(flow_sample[:,ind], color=cb2[2], bins=50, alpha=0.5, range=[-6,-2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reduce to power law indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "# make linear regression\n",
    "slope_1 = []\n",
    "intercept_1 = []\n",
    "Sx_coefficient = np.load(\"../Sx_all_mixed_dense.npy\")[:,:4]\n",
    "Sx_coefficient = np.log10(Sx_coefficient)\n",
    "for i in range(Sx_coefficient.shape[0]):\n",
    "    slope, intercept, dummy, dummy, dummy = stats.linregress(np.arange(Sx_coefficient.shape[1]),Sx_coefficient[i,:])\n",
    "    slope_1.append(slope)\n",
    "    intercept_1.append(intercept)\n",
    "slope_1 = np.array(slope_1)\n",
    "intercept_1 = np.array(intercept_1)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "# make linear regression\n",
    "slope_2 = []\n",
    "intercept_2 = []\n",
    "Sx_coefficient = np.load(\"../Sx_all_normal_dense.npy\")[:,:4]\n",
    "Sx_coefficient = np.log10(Sx_coefficient)\n",
    "\n",
    "for i in range(Sx_coefficient.shape[0]):\n",
    "    slope, intercept, dummy, dummy, dummy = stats.linregress(np.arange(Sx_coefficient.shape[1]),Sx_coefficient[i,:])\n",
    "    slope_2.append(slope)\n",
    "    intercept_2.append(intercept)\n",
    "slope_2 = np.array(slope_2)\n",
    "intercept_2 = np.array(intercept_2)\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "# plot results\n",
    "# plt.hist(slope_1, bins=50, alpha=0.5)\n",
    "# plt.hist(slope_2, bins=50, alpha=0.5)\n",
    "\n",
    "plt.hist(intercept_1, bins=50, alpha=0.5)\n",
    "plt.hist(intercept_2, bins=50, alpha=0.5)\n",
    "plt.xlabel(\"'Power Law' Slope\")\n",
    "plt.ylabel(\"Histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Investigate first scattering order coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the original light curve\n",
    "temp = np.load(\"../SDSS_DR14_qso_mock_normal_dense.npz\")\n",
    "real_spec = temp[\"light_curve\"][100]\n",
    "real_spec_2 = temp[\"light_curve\"][300]\n",
    "mixed_spec = (temp[\"light_curve\"][100] + temp[\"light_curve\"][300])/2.\n",
    "\n",
    "# substract the mean\n",
    "real_spec = real_spec - np.mean(real_spec)\n",
    "real_spec_2 = real_spec_2 - np.mean(real_spec_2)\n",
    "mixed_spec = mixed_spec - np.mean(mixed_spec)\n",
    "\n",
    "plt.plot(real_spec, label=\"Light Curve 1\")\n",
    "plt.plot(real_spec_2, label=\"Light Curve 2\")\n",
    "plt.plot(mixed_spec, label=\"Average light curve\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Flux\")\n",
    "plt.xlabel(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the fourier transform\n",
    "sp = np.fft.fft(real_spec)\n",
    "freq = np.fft.fftfreq(real_spec.shape[-1])\n",
    "\n",
    "# make frequency filtering\n",
    "choose = (np.abs(freq) > 0.02)*(np.abs(freq) < 0.04) == 0.\n",
    "sp[choose] = 0.\n",
    "\n",
    "plt.plot(freq, sp.real, freq, sp.imag)\n",
    "plt.ylim([-100,100])\n",
    "\n",
    "# make inverse transform\n",
    "real_spec_i = np.fft.ifft(sp)\n",
    "\n",
    "\n",
    "#==========================================================================\n",
    "# make the fourier transform\n",
    "sp = np.fft.fft(real_spec_2)\n",
    "freq = np.fft.fftfreq(real_spec_2.shape[-1])\n",
    "\n",
    "# make frequency filtering\n",
    "choose = (np.abs(freq) > 0.02)*(np.abs(freq) < 0.04) == 0.\n",
    "sp[choose] = 0.\n",
    "\n",
    "# make inverse transform\n",
    "real_spec_2_i = np.fft.ifft(sp)\n",
    "\n",
    "\n",
    "#==========================================================================\n",
    "# make the fourier transform\n",
    "sp = np.fft.fft(mixed_spec)\n",
    "freq = np.fft.fftfreq(mixed_spec.shape[-1])\n",
    "\n",
    "# make frequency filtering\n",
    "choose = (np.abs(freq) > 0.02)*(np.abs(freq) < 0.04) == 0.\n",
    "sp[choose] = 0.\n",
    "\n",
    "# make inverse transform\n",
    "mixed_spec_i = np.fft.ifft(sp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comparing the orignal light curve with the filtered version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_spec_i, label=\"Light Curve 1\")\n",
    "plt.plot(real_spec_2_i, label=\"Light Curve 2\")\n",
    "plt.plot(mixed_spec_i, label=\"Average light curve\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Flux\")\n",
    "plt.xlabel(\"Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check number of time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a ZTF time step\n",
    "temp = np.load(\"../SDSS_DR14_qso_mock_normal_sparse.npz\", allow_pickle=True)\n",
    "ztf_time = temp[\"t_array\"]\n",
    "time_length = np.array([ztf_time[i].size for i in range(ztf_time.size)])\n",
    "\n",
    "plt.hist(time_length)\n",
    "print(np.min(time_length))\n",
    "print(np.argmin(time_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Define analytically a method that can deal with irregular sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a ZTF time step\n",
    "temp = np.load(\"../SDSS_DR14_qso_mock_normal_sparse.npz\", allow_pickle=True)\n",
    "ztf_time = temp[\"t_array\"][133]\n",
    "ztf_time = np.unique((ztf_time*10).astype(\"int\"))\n",
    "print(ztf_time.shape)\n",
    "\n",
    "# plot the original light curve\n",
    "temp = np.load(\"../SDSS_DR14_qso_mock_normal_dense.npz\")\n",
    "time_stamp = temp[\"t_array\"][100,ztf_time]\n",
    "real_spec = temp[\"light_curve\"][100][ztf_time]\n",
    "real_spec_2 = temp[\"light_curve\"][300][ztf_time]\n",
    "mixed_spec = (temp[\"light_curve\"][100][ztf_time] + temp[\"light_curve\"][300][ztf_time])/2.\n",
    "\n",
    "# substract the mean\n",
    "real_spec = real_spec - np.mean(real_spec)\n",
    "real_spec_2 = real_spec_2 - np.mean(real_spec_2)\n",
    "mixed_spec = mixed_spec - np.mean(mixed_spec)\n",
    "\n",
    "# smooth the data\n",
    "plt.plot(time_stamp, real_spec, label=\"Light Curve 1\")\n",
    "plt.plot(time_stamp, real_spec_2, label=\"Light Curve 2\")\n",
    "plt.plot(time_stamp, mixed_spec, label=\"Average light curve\")\n",
    "plt.scatter(time_stamp, mixed_spec, s=30, color=\"black\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Flux\")\n",
    "plt.xlabel(\"Time [day]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a ZTF time step\n",
    "temp = np.load(\"../SDSS_DR14_qso_mock_normal_sparse.npz\", allow_pickle=True)\n",
    "ztf_time = temp[\"t_array\"][133]\n",
    "ztf_time = np.unique((ztf_time*10).astype(\"int\"))\n",
    "\n",
    "# plot the original light curve\n",
    "temp = np.load(\"../SDSS_DR14_qso_mock_normal_dense.npz\")\n",
    "time_stamp = temp[\"t_array\"][100,ztf_time]\n",
    "real_spec = temp[\"light_curve\"][100][ztf_time]\n",
    "real_spec_2 = temp[\"light_curve\"][300][ztf_time]\n",
    "mixed_spec = (temp[\"light_curve\"][100][ztf_time] + temp[\"light_curve\"][300][ztf_time])/2.\n",
    "\n",
    "# substract the mean\n",
    "real_spec = real_spec - np.mean(real_spec)\n",
    "real_spec_2 = real_spec_2 - np.mean(real_spec_2)\n",
    "mixed_spec = mixed_spec - np.mean(mixed_spec)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# choose windows of convolution (in unit of days)\n",
    "window_array = 10.**np.linspace(-1,2,7)[::-1]\n",
    "\n",
    "\n",
    "#====================================================================================================\n",
    "# make smooth template\n",
    "real_spec_smooth = np.copy(real_spec)\n",
    "real_spec_2_smooth = np.copy(real_spec_2)\n",
    "mixed_spec_smooth = np.copy(mixed_spec)\n",
    "\n",
    "# loop over all pixels\n",
    "for i in range(real_spec.size):    \n",
    "\n",
    "    choose = np.abs(time_stamp - time_stamp[i]) < window_array[0]\n",
    "    real_spec_smooth[i] = np.mean(real_spec[choose])\n",
    "    real_spec_2_smooth[i] = np.mean(real_spec_2[choose])\n",
    "    mixed_spec_smooth[i] = np.mean(mixed_spec[choose])\n",
    "\n",
    "# substract away this frequency scale\n",
    "real_spec = real_spec - real_spec_smooth\n",
    "real_spec_2 = real_spec_2 - real_spec_2_smooth\n",
    "mixed_spec = mixed_spec - mixed_spec_smooth\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# plot the smooth function\n",
    "plt.figure()\n",
    "plt.plot(real_spec, label=\"Light Curve 1\")\n",
    "plt.plot(real_spec_2, label=\"Light Curve 2\")\n",
    "plt.plot(mixed_spec, label=\"Average light curve\")\n",
    "\n",
    "\n",
    "#====================================================================================================\n",
    "# make smooth template\n",
    "real_spec_smooth = np.copy(real_spec)\n",
    "real_spec_2_smooth = np.copy(real_spec_2)\n",
    "mixed_spec_smooth = np.copy(mixed_spec)\n",
    "\n",
    "# loop over all pixels\n",
    "for i in range(real_spec.size):    \n",
    "\n",
    "    choose = np.abs(time_stamp - time_stamp[i]) < window_array[1]\n",
    "    real_spec_smooth[i] = np.mean(real_spec[choose])\n",
    "    real_spec_2_smooth[i] = np.mean(real_spec_2[choose])\n",
    "    mixed_spec_smooth[i] = np.mean(mixed_spec[choose])\n",
    "\n",
    "# substract away this frequency scale\n",
    "real_spec = real_spec - real_spec_smooth\n",
    "real_spec_2 = real_spec_2 - real_spec_2_smooth\n",
    "mixed_spec = mixed_spec - mixed_spec_smooth\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# plot the smooth function\n",
    "plt.figure()\n",
    "plt.plot(real_spec, label=\"Light Curve 1\")\n",
    "plt.plot(real_spec_2, label=\"Light Curve 2\")\n",
    "plt.plot(mixed_spec, label=\"Average light curve\")\n",
    "\n",
    "\n",
    "#====================================================================================================\n",
    "# make smooth template\n",
    "real_spec_smooth = np.copy(real_spec)\n",
    "real_spec_2_smooth = np.copy(real_spec_2)\n",
    "mixed_spec_smooth = np.copy(mixed_spec)\n",
    "\n",
    "# loop over all pixels\n",
    "for i in range(real_spec.size):    \n",
    "\n",
    "    choose = np.abs(time_stamp - time_stamp[i]) < window_array[2]\n",
    "    real_spec_smooth[i] = np.mean(real_spec[choose])\n",
    "    real_spec_2_smooth[i] = np.mean(real_spec_2[choose])\n",
    "    mixed_spec_smooth[i] = np.mean(mixed_spec[choose])\n",
    "\n",
    "# substract away this frequency scale\n",
    "real_spec = real_spec - real_spec_smooth\n",
    "real_spec_2 = real_spec_2 - real_spec_2_smooth\n",
    "mixed_spec = mixed_spec - mixed_spec_smooth\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "# plot the smooth function\n",
    "plt.figure()\n",
    "plt.plot(real_spec, label=\"Light Curve 1\")\n",
    "plt.plot(real_spec_2, label=\"Light Curve 2\")\n",
    "plt.plot(mixed_spec, label=\"Average light curve\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sample log probablity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    "#========================================================================================================\n",
    "# read scattering coefficents\n",
    "y_tr = np.load(\"../Sx_all_mixed_dense.npy\")\n",
    "y_tr = np.log10(y_tr)\n",
    "\n",
    "# exclude entries with nan (no small scale)\n",
    "valid_entry = []\n",
    "for i in range(y_tr.shape[0]):\n",
    "    if np.sum(np.isfinite(y_tr[i,:])) == y_tr.shape[1]:\n",
    "        valid_entry.append(i)\n",
    "y_tr = y_tr[valid_entry,:]\n",
    "print(y_tr.shape)\n",
    "\n",
    "# convert into torch\n",
    "y_tr = torch.from_numpy(y_tr).type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "#=======================================================================================================\n",
    "# In [2]:\n",
    "# define normalizing flow\n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, nets, nett, mask, prior):\n",
    "        super(RealNVP, self).__init__()\n",
    "\n",
    "        self.prior = prior\n",
    "        self.mask = nn.Parameter(mask, requires_grad=False)\n",
    "        self.t = torch.nn.ModuleList([nett() for _ in range(len(masks))])\n",
    "        self.s = torch.nn.ModuleList([nets() for _ in range(len(masks))])\n",
    "\n",
    "    def g(self, z):\n",
    "        x = z\n",
    "        for i in range(len(self.t)):\n",
    "            x_ = x*self.mask[i]\n",
    "            s = self.s[i](x_)*(1 - self.mask[i])\n",
    "            t = self.t[i](x_)*(1 - self.mask[i])\n",
    "            x = x_ + (1 - self.mask[i]) * (x * torch.exp(s) + t)\n",
    "        return x\n",
    "\n",
    "    def f(self, x):\n",
    "        log_det_J, z = x.new_zeros(x.shape[0]), x\n",
    "        for i in reversed(range(len(self.t))):\n",
    "            z_ = self.mask[i] * z\n",
    "            s = self.s[i](z_) * (1-self.mask[i])\n",
    "            t = self.t[i](z_) * (1-self.mask[i])\n",
    "            z = (1 - self.mask[i]) * (z - t) * torch.exp(-s) + z_\n",
    "            log_det_J -= s.sum(dim=1)\n",
    "        return z, log_det_J\n",
    "\n",
    "    def log_prob(self,x):\n",
    "        z, logp = self.f(x)\n",
    "        return self.prior.log_prob(z) + logp\n",
    "\n",
    "    def sample(self, z):\n",
    "        x = self.g(z)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "#==================================================================================\n",
    "# restore models\n",
    "flow = torch.load(\"../flow_final_dense.pt\", map_location=lambda storage, loc: storage) # load in cpu\n",
    "flow.eval()\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "# sample results\n",
    "log_prob_x = flow.log_prob(y_tr).detach().numpy()\n",
    "\n",
    "# save results\n",
    "np.savez(\"../real_nvp_results_light_curve_mixed_dense.npz\",\\\n",
    "         log_prob_x = log_prob_x)\n",
    "\n",
    "print(log_prob_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.load(\"../real_nvp_results_light_curve_validation_dense.npz\")\n",
    "plt.hist(temp[\"log_prob_x\"], bins=50, label=\"validation\", alpha=0.5, range=[-50,30], normed=True);\n",
    "\n",
    "temp = np.load(\"../real_nvp_results_light_curve_normal_dense.npz\")\n",
    "plt.hist(temp[\"log_prob_x\"], bins=50, label=\"training\", alpha=0.5, range=[-50,30], normed=True);\n",
    "\n",
    "temp = np.load(\"../real_nvp_results_light_curve_mixed_dense.npz\")\n",
    "plt.hist(temp[\"log_prob_x\"], bins=50, label=\"mixed\", alpha=0.5, range=[-50,30], normed=True);\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"log probability\")\n",
    "plt.ylabel(\"# light curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Processes inputation.\n",
    "\n",
    "> Run with GPy. First a simple example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import GPy\n",
    "\n",
    "# make mock data\n",
    "X = np.random.uniform(-3.,3.,(20,1))\n",
    "Y = np.sin(X) + np.random.randn(20,1)*0.05\n",
    "\n",
    "# define kernel\n",
    "kernel = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)\n",
    "m = GPy.models.GPRegression(X,Y,kernel)\n",
    "\n",
    "# optimize\n",
    "m.optimize(messages=True)\n",
    "m.optimize_restarts(num_restarts = 10)\n",
    "\n",
    "# display results\n",
    "fig = m.plot(plot_density=True)\n",
    "GPy.plotting.show(fig, filename='basic_gp_regression_density_notebook_optimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make prediction with the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,Y)\n",
    "\n",
    "X_array = np.linspace(-4,4,100)\n",
    "X_array = X_array.reshape(X_array.size,1)\n",
    "\n",
    "Y_predict = np.array(m.predict(X_array))[0,:,:]\n",
    "plt.plot(X_array,Y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Try with real light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "\n",
    "# load light curve\n",
    "temp = np.load(\"../light_curve.npz\")\n",
    "light_curve = temp[\"light_curve\"]\n",
    "t_array = temp[\"t_array\"]\n",
    "\n",
    "# extract a single light cure\n",
    "X = t_array[0,:]\n",
    "X = X.reshape(X.size,-1)\n",
    "Y = light_curve[0,:]\n",
    "Y = Y.reshape(Y.size,-1)\n",
    "\n",
    "# define kernel\n",
    "kernel = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)\n",
    "m = GPy.models.GPRegression(X[::10],Y[::10],kernel)\n",
    "\n",
    "# optimize\n",
    "m.optimize(messages=True)\n",
    "m.optimize_restarts(num_restarts = 10)\n",
    "\n",
    "# display results\n",
    "fig = m.plot(plot_density=True)\n",
    "GPy.plotting.show(fig, filename='basic_gp_regression_density_notebook_optimized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_array[0,:],light_curve[0,:], color=cb2[1])\n",
    "\n",
    "X_array = t_array[0,:]\n",
    "X_array = X_array.reshape(X_array.size,1)\n",
    "\n",
    "Y_predict = np.array(m.predict(X_array))[0,:,0]\n",
    "Y_std = np.sqrt(np.array(m.predict(X_array))[1,:,0])\n",
    "\n",
    "plt.plot(X_array[:,0],Y_predict, color=\"black\")\n",
    "plt.fill_between(X_array[:,0], Y_predict-Y_std, Y_predict+Y_std, color=cb2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDSS DR14 QSO.\n",
    "\n",
    "> Read data files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all flies\n",
    "import os\n",
    "list_files = os.listdir(\"../qso\")\n",
    "\n",
    "# initiate array\n",
    "mjd_g = []\n",
    "g_array = []\n",
    "mjd_r = []\n",
    "r_array = []\n",
    "list_files_store = []\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# loop over all files\n",
    "for i in range(len(list_files)):\n",
    "        \n",
    "    try:\n",
    "        # read data\n",
    "        data = np.loadtxt(\"../qso/\" + list_files[i])\n",
    "        mjd_g_temp = data[:,2]\n",
    "        g_temp = data[:,3]\n",
    "        mjd_r_temp = data[:,0]\n",
    "        r_temp = data[:,1]\n",
    "    \n",
    "        # cull empty entries and sort by time\n",
    "        choose = mjd_g_temp > 10.\n",
    "        mjd_g_temp = mjd_g_temp[choose]\n",
    "        g_temp = g_temp[choose]\n",
    "        choose = np.argsort(mjd_g_temp)\n",
    "        mjd_g_temp = mjd_g_temp[choose]\n",
    "        g_temp = g_temp[choose]\n",
    "    \n",
    "        choose = mjd_r_temp > 10.\n",
    "        mjd_r_temp = mjd_r_temp[choose]\n",
    "        r_temp = r_temp[choose]\n",
    "        choose = np.argsort(mjd_r_temp)\n",
    "        mjd_r_temp = mjd_r_temp[choose]\n",
    "        r_temp = r_temp[choose]\n",
    "\n",
    "        # record results\n",
    "        mjd_g.append(mjd_g_temp)\n",
    "        g_array.append(g_temp)\n",
    "        mjd_r.append(mjd_r_temp)\n",
    "        r_array.append(r_temp)\n",
    "        list_files_store.append(list_files[i])\n",
    "        \n",
    "    except:\n",
    "        print(i)\n",
    "\n",
    "# convert to numpy array\n",
    "mjd_g = np.array(mjd_g)\n",
    "g_array = np.array(g_array)\n",
    "mjd_r = np.array(mjd_r)\n",
    "r_array = np.array(r_array)\n",
    "list_files = np.array(list_files_store)\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# save results\n",
    "np.savez(\"../SDSS_DR14_qso.npz\",\\\n",
    "         mjd_g = mjd_g,\\\n",
    "         g_array = g_array,\\\n",
    "         mjd_r = mjd_r,\\\n",
    "         r_array = r_array,\\\n",
    "         list_files = list_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Investigate the time stamp range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time step range\n",
    "mjd_g_range = np.array([mjd_g[i][-1]-mjd_g[i][0] for i in range(mjd_g.size)])\n",
    "mjd_r_range = np.array([mjd_r[i][-1]-mjd_r[i][0] for i in range(mjd_g.size)])\n",
    "\n",
    "plt.hist(mjd_g_range, bins=100, range=[400,500]);\n",
    "plt.hist(mjd_r_range, bins=100, range=[400,500]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time step recorded\n",
    "mjd_g_range = np.array([len(mjd_g[i]) for i in range(mjd_g.size)])\n",
    "mjd_r_range = np.array([len(mjd_r[i]) for i in range(mjd_g.size)])\n",
    "\n",
    "plt.hist(mjd_g_range, bins=100);\n",
    "plt.hist(mjd_r_range, bins=100);\n",
    "\n",
    "#print(np.where(mjd_g_range > 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Try Gaussian Processes on light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#==================================================================================\n",
    "### restore mock grid ###\n",
    "temp = np.load(\"../SDSS_DR14_qso_mock_normal_dense.npz\", allow_pickle=True)\n",
    "mjd_g = temp[\"t_array\"][:,::100]\n",
    "g_array = temp[\"light_curve\"][:,::100]\n",
    "\n",
    "\n",
    "#==================================================================================\n",
    "# choose one object\n",
    "ind_choose = 0\n",
    "\n",
    "# extract a single light cure\n",
    "X = (mjd_g[ind_choose] - mjd_g[ind_choose][0])\n",
    "X = X.reshape(X.size,-1)\n",
    "Y = g_array[ind_choose]\n",
    "Y = Y.reshape(Y.size,-1)\n",
    "\n",
    "# define kernel\n",
    "k0 = GPy.kern.Matern32(1) \n",
    "k1 = GPy.kern.Matern32(1) \n",
    "k2 = GPy.kern.Matern32(1) \n",
    "\n",
    "#kernel = k0 + k1 + k2 \n",
    "kernel = k0 \n",
    "m = GPy.models.GPRegression(X, Y, kernel, normalizer=True)\n",
    "#print(m.kern)\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# set range parameters\n",
    "# m.kern.Mat32.lengthscale.constrain_bounded(0.1,1)\n",
    "# m.kern.Mat32.variance.constrain_bounded(1e-10,1e-5)\n",
    "\n",
    "# m.kern.Mat32_1.lengthscale.constrain_bounded(1,10)\n",
    "# m.kern.Mat32_1.variance.constrain_bounded(1e-10,1e-5)\n",
    "\n",
    "# m.kern.Mat32_2.lengthscale.constrain_bounded(10,100)\n",
    "# m.kern.Mat32_2.variance.constrain_bounded(1e-10,1.)\n",
    "\n",
    "# Fix the noise variance to known value \n",
    "#m.Gaussian_noise.variance = 1e-3**2\n",
    "#m.Gaussian_noise.variance.fix()\n",
    "\n",
    "# optimize\n",
    "m.optimize(messages=True)\n",
    "m.optimize_restarts(num_restarts = 10)\n",
    "print(m.kern)\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# extract parameters\n",
    "# lengthscale_array = np.array([m.kern.Mat32.lengthscale[0],\\\n",
    "#                          m.kern.Mat32_1.lengthscale[0],\\\n",
    "#                          m.kern.Mat32_2.lengthscale[0]])\n",
    "# variance_array = np.array([m.kern.Mat32.variance[0],\\\n",
    "#                          m.kern.Mat32_1.variance[0],\\\n",
    "#                          m.kern.Mat32_2.variance[0]])\n",
    "\n",
    "# # sort by lengthscale\n",
    "# length_sort = np.argsort(lengthscale_array)\n",
    "# lengthscale_array = lengthscale_array[length_sort]\n",
    "# variance_array = variance_array[length_sort]\n",
    "\n",
    "# # combine all parameters\n",
    "# kernel_param = np.concatenate([lengthscale_array,variance_array])\n",
    "# print(kernel_param)\n",
    "\n",
    "### assuming just one kernel\n",
    "kernel_param = np.concatenate([m.kern.lengthscale,m.kern.variance])\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# display results\n",
    "fig = m.plot(plot_density=True)\n",
    "GPy.plotting.show(fig, filename='basic_gp_regression_density_notebook_optimized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set grid to interpolate into\n",
    "X_array = np.arange(5120)*0.1\n",
    "X_array = X_array.reshape(X_array.size,1)\n",
    "\n",
    "# make prediction\n",
    "Y_predict = np.array(m.predict(X_array))[0,:,0]\n",
    "Y_std = np.sqrt(np.array(m.predict(X_array))[1,:,0])\n",
    "\n",
    "# original data\n",
    "plt.scatter(temp[\"t_array\"][ind_choose,:], temp[\"light_curve\"][ind_choose,:], color=cb2[1], s=1)\n",
    "plt.xlim([100,200])\n",
    "# prediction\n",
    "plt.plot(X_array[:,0],Y_predict, color=\"black\", lw=2)\n",
    "#plt.fill_between(X_array[:,0], Y_predict-Y_std, Y_predict+Y_std, color=cb2[0], alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check time step gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore grid\n",
    "temp = np.load(\"../SDSS_DR14_qso.npz\", allow_pickle=True)\n",
    "mjd_g = temp[\"mjd_g\"]\n",
    "mjd_gap = []\n",
    "for i in range(mjd_g.size):\n",
    "    mjd_gap.extend(mjd_g[i][1:]-mjd_g[i][:-1])\n",
    "mjd_gap = np.array(mjd_gap)\n",
    "print(mjd_gap.size)\n",
    "plt.hist(mjd_gap, bins=100, range=[0,0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Gaussian Processes in batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Processes package\n",
    "import GPy\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# set number of threads per CPU\n",
    "os.environ['OMP_NUM_THREADS']='{:d}'.format(1)\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# restore grid\n",
    "# temp = np.load(\"../SDSS_DR14_qso.npz\", allow_pickle=True)\n",
    "# mjd_g = temp[\"mjd_g\"]\n",
    "# g_array = temp[\"g_array\"]\n",
    "\n",
    "### restore mock grid ###\n",
    "temp = np.load(\"../SDSS_DR14_qso_mock.npz\", allow_pickle=True)\n",
    "mjd_g = temp[\"t_array\"]\n",
    "g_array = temp[\"light_curve\"]\n",
    "\n",
    "# set grid to interpolate into\n",
    "# X_array = np.arange(5120)*0.1\n",
    "# X_array = X_array.reshape(X_array.size,1)\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# interpolate with GP\n",
    "def GP_interp(ind_choose):\n",
    "\n",
    "    # extract a single light cure\n",
    "    X = (mjd_g[ind_choose] - mjd_g[ind_choose][0])\n",
    "    X = X.reshape(X.size,-1)\n",
    "    Y = g_array[ind_choose]\n",
    "    Y = Y.reshape(Y.size,-1)\n",
    "\n",
    "    # define kernel\n",
    "    k0 = GPy.kern.Matern32(1) \n",
    "    k1 = GPy.kern.Matern32(1) \n",
    "    k2 = GPy.kern.Matern32(1) \n",
    "    kernel = k0 + k1 + k2 \n",
    "    \n",
    "#-------------------------------------------------------------------------------------\n",
    "    # define regression\n",
    "    m = GPy.models.GPRegression(X, Y, kernel, normalizer=True)\n",
    "\n",
    "    # set range parameters\n",
    "#     m.kern.Mat32.lengthscale.constrain_bounded(0.1,1)\n",
    "#     m.kern.Mat32.variance.constrain_bounded(1e-10,1e-5)\n",
    "\n",
    "#     m.kern.Mat32_1.lengthscale.constrain_bounded(1,10)\n",
    "#     m.kern.Mat32_1.variance.constrain_bounded(1e-10,1e-5)\n",
    "\n",
    "#     m.kern.Mat32_2.lengthscale.constrain_bounded(10,100)\n",
    "#     m.kern.Mat32_2.variance.constrain_bounded(1e-10,1.)\n",
    "\n",
    "    # fix the noise variance to known value \n",
    "#     m.Gaussian_noise.variance = 1e-2**2\n",
    "#     m.Gaussian_noise.variance.fix()\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "    # optimize\n",
    "    m.optimize(messages=True)\n",
    "    m.optimize_restarts(num_restarts = 10)\n",
    "\n",
    "    # make prediction\n",
    "    #Y_predict = np.array(m.predict(X_array))[0,:,0]\n",
    "    \n",
    "#-------------------------------------------------------------------------------------\n",
    "    # extract parameters\n",
    "    lengthscale_array = np.array([m.kern.Mat32.lengthscale[0],\\\n",
    "                                  m.kern.Mat32_1.lengthscale[0],\\\n",
    "                                  m.kern.Mat32_2.lengthscale[0]])\n",
    "    variance_array = np.array([m.kern.Mat32.variance[0],\\\n",
    "                               m.kern.Mat32_1.variance[0],\\\n",
    "                               m.kern.Mat32_2.variance[0]])\n",
    "\n",
    "    # sort by lengthscale\n",
    "    length_sort = np.argsort(lengthscale_array)\n",
    "    lengthscale_array = lengthscale_array[length_sort]\n",
    "    variance_array = variance_array[length_sort]\n",
    "\n",
    "    # combine all parameters\n",
    "    Y_predict = np.concatenate([lengthscale_array,variance_array])\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "    # return prediction\n",
    "    return Y_predict\n",
    "\n",
    "\n",
    "#=====================================================================================\n",
    "# number of CPU to run in parallel\n",
    "num_CPU = 4\n",
    "pool = Pool(num_CPU)\n",
    "start_time = time.time()\n",
    "Y_predict_array = np.array(pool.map(GP_interp,range(mjd_g.size)))\n",
    "print(time.time()-start_time)\n",
    "    \n",
    "# save results\n",
    "np.save(\"../kernel_param_mock.npy\", np.array(Y_predict_array))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot kernel parameter distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_param = np.load(\"../kernel_param_mock.npy\")\n",
    "plt.hist(kernel_param[:,5],bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.load(\"../loss_results.npz\")\n",
    "plt.plot(temp[\"loss_array\"])\n",
    "plt.ylim([-500,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lomb Sargles as representations.\n",
    "\n",
    "> Using Lomb Scargles as a metric.\n",
    "\n",
    "Cannot use the interpolated version, because the Gaussian kernel period will imprint on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.timeseries import LombScargle\n",
    "from scipy import interpolate\n",
    "\n",
    "# choose a frequency grid to interpolate into\n",
    "frequency_interp = np.arange(1201)/1200.*0.6\n",
    "\n",
    "\n",
    "#====================================================================================\n",
    "# restore grid\n",
    "#temp = np.load(\"../SDSS_DR14_qso.npz\", allow_pickle=True)\n",
    "#mjd_g = temp[\"mjd_g\"]\n",
    "#g_array = temp[\"g_array\"]\n",
    "\n",
    "temp = np.load(\"../SDSS_DR14_qso_mock_normal_dense.npz\", allow_pickle=True)\n",
    "mjd_g = temp[\"t_array\"]\n",
    "g_array = temp[\"light_curve\"]\n",
    "\n",
    "\n",
    "#====================================================================================\n",
    "# initiate result arrays\n",
    "power_array = []\n",
    "\n",
    "# loop over all objects\n",
    "for i in range(g_array.shape[0]):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    frequency, power = LombScargle(mjd_g[i], g_array[i]).autopower(method='fast')\n",
    "    #frequency, power = LombScargle(mjd_g[i], g_array[i]).autopower(method='slow')\n",
    "    \n",
    "    f_power = interpolate.interp1d(frequency, power, bounds_error=False, fill_value=0.)\n",
    "    power_array.append(f_power(frequency_interp))\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# convert to numpy array\n",
    "power_array = np.array(power_array)\n",
    "\n",
    "# sum up power\n",
    "power_added = np.zeros((power_array.shape[0],12))\n",
    "for j in range(power_array.shape[0]):\n",
    "    for i in range(12):\n",
    "        power_added[j,i] = np.sum(power_array[j,i*100:(i+1)*100])\n",
    "        \n",
    "# save results\n",
    "np.savez(\"../g_lomb_scargle_normal_dense.npz\",\\\n",
    "         frequency_interp = frequency_interp,\\\n",
    "         power_array = power_array,\\\n",
    "         power_added = power_added)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.load(\"../g_lomb_scargle_normal_dense.npz\")\n",
    "frequency_interp = temp[\"frequency_interp\"]\n",
    "power_array = temp[\"power_array\"]\n",
    "power_added = temp[\"power_added\"]\n",
    "\n",
    "plt.plot(frequency_interp, power_array[0,:])\n",
    "#plt.plot(frequency_interp[::100][:-1], power_added[0,:])\n",
    "#for i in range(1000):\n",
    "#    plt.plot(frequency_interp[::100][:-1], power_added[i,:], color=cb2[0], alpha=0.01)\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# temp = np.load(\"../g_lomb_scargle_validation.npz\")\n",
    "# frequency_interp = temp[\"frequency_interp\"]\n",
    "# power_array = temp[\"power_array\"]\n",
    "# power_added = temp[\"power_added\"]\n",
    "\n",
    "# for i in range(1000):\n",
    "#     plt.plot(frequency_interp[::100][:-1], power_added[i,:], color=cb2[1], alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check mock SDSS qso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore grid\n",
    "temp = np.load(\"../SDSS_DR14_qso_mock.npz\", allow_pickle=True)\n",
    "mjd_g = temp[\"t_array\"]\n",
    "g_array = temp[\"light_curve\"]\n",
    "\n",
    "ind_choose = 90\n",
    "print(mjd_g[ind_choose].size)\n",
    "plt.scatter(mjd_g[ind_choose],g_array[ind_choose])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
