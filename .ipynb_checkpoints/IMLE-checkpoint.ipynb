{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# import packages\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define plot properties\n",
    "from cycler import cycler\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import rc\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def rgb(r,g,b):\n",
    "    return (float(r)/256.,float(g)/256.,float(b)/256.)\n",
    "\n",
    "cb2 = [rgb(31,120,180), rgb(255,127,0), rgb(51,160,44), rgb(227,26,28), \\\n",
    "       rgb(166,206,227), rgb(253,191,111), rgb(178,223,138), rgb(251,154,153)]\n",
    "\n",
    "rcParams['figure.figsize'] = (9,7.5)\n",
    "#rcParams['figure.dpi'] = 300\n",
    "\n",
    "rcParams['lines.linewidth'] = 1\n",
    "\n",
    "rcParams['axes.prop_cycle'] = cycler('color', cb2)\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['axes.grid'] = False\n",
    "\n",
    "rcParams['patch.facecolor'] = cb2[0]\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "\n",
    "#rcParams['font.family'] = 'Bitstream Vera Sans' \n",
    "rcParams['font.size'] = 23\n",
    "rcParams['font.weight'] = 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the array\n",
    "arr = np.load(\"../DES_DR1.npy\")\n",
    "\n",
    "# permute the data\n",
    "rng = np.random.RandomState(seed=42)\n",
    "pidx = rng.permutation(len(arr))\n",
    "arr = arr[pidx]\n",
    "    \n",
    "# crop the image\n",
    "arr = arr[:,32:96,32:96,:]\n",
    "\n",
    "# scale data\n",
    "arr = np.clip(np.arcsinh(0.01*arr)+0.4,0,5)/5\n",
    "\n",
    "# further scale to make the color pop\n",
    "arr[:,:,:,0] = arr[:,:,:,0] * 1.5\n",
    "arr[:,:,:,1] = arr[:,:,:,1] * 1.2\n",
    "arr[:,:,:,2] = arr[:,:,:,2] * 1.1\n",
    "arr = np.clip(arr,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a channel of an image\n",
    "channel_choice = 2\n",
    "\n",
    "# choose an image\n",
    "image_choice = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Histogram of individual channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(arr[:,:,:,0].ravel(), alpha=0.5, bins=100);\n",
    "plt.hist(arr[:,:,:,1].ravel(), alpha=0.5, bins=100);\n",
    "plt.hist(arr[:,:,:,2].ravel(), alpha=0.5, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Show images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(arr[image_choice,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore results\n",
    "import imageio\n",
    "\n",
    "# choose a subset of images\n",
    "X = arr[:64]\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot the tiled results\n",
    "n_samples = X.shape[0]\n",
    "rows = int(np.sqrt(n_samples))\n",
    "while n_samples % rows != 0:\n",
    "    rows -= 1\n",
    "\n",
    "nh, nw = rows, int(n_samples/rows)\n",
    "\n",
    "h, w = X[0].shape[:2]\n",
    "img = np.zeros((h*nh, w*nw, 3))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# loop over all images\n",
    "for n, x in enumerate(X):\n",
    "    j = int(n/nw)\n",
    "    i = n%nw\n",
    "    x_temp = np.copy(x)\n",
    "    img[j*h:j*h+h, i*w:i*w+w, :] = x_temp\n",
    "\n",
    "# save images\n",
    "imageio.imwrite(\"Results.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training set\n",
    "arr = np.swapaxes(arr,3,1)\n",
    "np.save(\"../training_set_des.npy\", arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Restore 2D networks and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore results\n",
    "temp = np.load(\"../results_2D.npz\")\n",
    "data_np = temp[\"data_np\"]\n",
    "plt.hist(np.log(data_np).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# restore results\n",
    "import imageio\n",
    "\n",
    "# restore results\n",
    "# temp = np.load(\"../results_2D_zdim=4.npz\")\n",
    "# samples_np = temp[\"samples_np\"][::10][:100,:]\n",
    "\n",
    "temp = np.load(\"../results_2D_random_zdim=4.npz\")\n",
    "samples_np = temp[\"samples_np\"][:100,:]\n",
    "\n",
    "# swap channel axis\n",
    "X = np.swapaxes(samples_np,3,1)\n",
    "X = np.clip(X,0.1,1.)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot the tiled results\n",
    "n_samples = X.shape[0]\n",
    "rows = int(np.sqrt(n_samples))\n",
    "while n_samples % rows != 0:\n",
    "    rows -= 1\n",
    "\n",
    "nh, nw = rows, int(n_samples/rows)\n",
    "\n",
    "h, w = X[0].shape[:2]\n",
    "img = np.zeros((h*nh, w*nw, 3))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# loop over all images\n",
    "for n, x in enumerate(X):\n",
    "    j = int(n/nw)\n",
    "    i = n%nw\n",
    "    x_temp = np.copy(x)\n",
    "    img[j*h:j*h+h, i*w:i*w+w, :] = x_temp\n",
    "\n",
    "# save images\n",
    "imageio.imwrite(\"../Results_2D_mock.png\", img)\n",
    "\n",
    "\n",
    "#==============================================================================\n",
    "# restore results\n",
    "import imageio\n",
    "\n",
    "# restore results\n",
    "temp = np.load(\"../results_2D_zdim=4.npz\")\n",
    "data_np = temp[\"data_np\"][::10,:][:100,:]\n",
    "\n",
    "# swap channel axis\n",
    "X = np.swapaxes(data_np,3,1)\n",
    "X = np.clip(X,0.1,1.)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot the tiled results\n",
    "n_samples = X.shape[0]\n",
    "rows = int(np.sqrt(n_samples))\n",
    "\n",
    "while n_samples % rows != 0:\n",
    "    rows -= 1\n",
    "\n",
    "nh, nw = rows, int(n_samples/rows)\n",
    "\n",
    "h, w = X[0].shape[:2]\n",
    "img = np.zeros((h*nh, w*nw, 3))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# loop over all images\n",
    "for n, x in enumerate(X):\n",
    "    j = int(n/nw)\n",
    "    i = n%nw\n",
    "    x_temp = np.copy(x)\n",
    "    img[j*h:j*h+h, i*w:i*w+w, :] = x_temp\n",
    "\n",
    "# save images\n",
    "imageio.imwrite(\"../Results_2D_real.png\", img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Restore 3D networks and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore results\n",
    "import imageio\n",
    "\n",
    "# restore results\n",
    "temp = np.load(\"../results_3D.npz\")\n",
    "samples_np = temp[\"samples_np\"][0,0,:,:,:]\n",
    "data_np = temp[\"data_np\"][0,0,:,:,:]\n",
    "\n",
    "# set range\n",
    "X = np.clip(samples_np,5.,10.)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot the tiled results\n",
    "n_samples = X.shape[0]\n",
    "rows = int(np.sqrt(n_samples))\n",
    "while n_samples % rows != 0:\n",
    "    rows -= 1\n",
    "\n",
    "nh, nw = rows, int(n_samples/rows)\n",
    "\n",
    "h, w = X[0].shape[:2]\n",
    "img = np.zeros((h*nh, w*nw))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# loop over all images\n",
    "for n, x in enumerate(X):\n",
    "    j = int(n/nw)\n",
    "    i = n%nw\n",
    "    x_temp = np.copy(x)\n",
    "    img[j*h:j*h+h, i*w:i*w+w] = x_temp\n",
    "\n",
    "# save images\n",
    "imageio.imwrite(\"../Results_3D_mock.png\", img)\n",
    "\n",
    "\n",
    "#==============================================================================\n",
    "# restore results\n",
    "import imageio\n",
    "\n",
    "# restore results\n",
    "temp = np.load(\"../results_3D.npz\")\n",
    "samples_np = temp[\"samples_np\"][0,0,:,:,:]\n",
    "data_np = temp[\"data_np\"][0,0,:,:,:]\n",
    "\n",
    "# set range\n",
    "X = np.clip(data_np,5.,10.)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot the tiled results\n",
    "n_samples = X.shape[0]\n",
    "rows = int(np.sqrt(n_samples))\n",
    "\n",
    "while n_samples % rows != 0:\n",
    "    rows -= 1\n",
    "\n",
    "nh, nw = rows, int(n_samples/rows)\n",
    "\n",
    "h, w = X[0].shape[:2]\n",
    "img = np.zeros((h*nh, w*nw))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# loop over all images\n",
    "for n, x in enumerate(X):\n",
    "    j = int(n/nw)\n",
    "    i = n%nw\n",
    "    x_temp = np.copy(x)\n",
    "    img[j*h:j*h+h, i*w:i*w+w] = x_temp\n",
    "\n",
    "# save images\n",
    "imageio.imwrite(\"../Results_3D_real.png\", img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(samples_np[10,0,slice,:,:], vmin=5, vmax=10, cmap=\"Greys\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples_np.shape)\n",
    "print(data_np.shape)\n",
    "plt.hist(samples_np.flatten(), bins=100);\n",
    "plt.hist(data_np.flatten(), bins=100, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate Zeldovich Approximation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore data\n",
    "temp = np.load(\"../Zeldovich_Approximation.npz\")\n",
    "sim_z0 = temp[\"sim_z0\"]\n",
    "sim_z0 = sim_z0.reshape(sim_z0.shape[0]*sim_z0.shape[1],1,sim_z0.shape[2],sim_z0.shape[3])\n",
    "sim_z0 = sim_z0[:,:,::2,::2][:,:,2:-2,2:-2]\n",
    "print(sim_z0.shape)\n",
    "sim_z50 = temp[\"sim_z50\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate NN structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0a8c5d152f8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# load previous model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m state_dict = torch.load(\"../checkpoint_single_channel_init_later.pth.tar\",\\\n\u001b[0;32m---> 63\u001b[0;31m                         map_location=torch.device('cpu'))\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mimle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'encoding'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imle'"
     ]
    }
   ],
   "source": [
    "# import package\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# define network\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "class DeeperConvImplicitModel(torch.nn.Module):\n",
    "    def __init__(self, z_dim, init_weight_factor = 1.):\n",
    "        super(DeeperConvImplicitModel, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.init_weight_factor = init_weight_factor\n",
    "\n",
    "        layers = [View((-1,z_dim,1,1))]\n",
    "\n",
    "        for i in range(4):\n",
    "\n",
    "            for j in range(5):\n",
    "\n",
    "                if i == 0 and j == 0:\n",
    "                    layers.append(torch.nn.ConvTranspose2d(z_dim, 512, 4, stride=1, padding=0))\n",
    "                    layers.append(torch.nn.BatchNorm2d(512, momentum=0.001, affine=False))\n",
    "                    layers.append(torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "                else:\n",
    "                    layers.append(torch.nn.Conv2d(512, 512, 5, stride=1, padding=2))\n",
    "                    layers.append(torch.nn.BatchNorm2d(512, momentum=0.001, affine=False))\n",
    "                    layers.append(torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "            if i < 3:\n",
    "                layers.append(torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners = False))\n",
    "            else:\n",
    "                layers.append(torch.nn.Conv2d(512, 3, 5, stride=1, padding=2))\n",
    "                layers.append(torch.nn.Sigmoid())\n",
    "\n",
    "        self.model = torch.nn.Sequential(*layers)\n",
    "        self.add_module(\"model\", self.model)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "    \n",
    "#----------------------------------------------------------------------------------------\n",
    "class IMLE():\n",
    "    def __init__(self, z_dim):\n",
    "        self.z_dim = z_dim\n",
    "        self.model = DeeperConvImplicitModel(z_dim)\n",
    "        \n",
    "    \n",
    "#========================================================================================\n",
    "# initate model\n",
    "z_dim = 64\n",
    "batch_size = 2        \n",
    "imle = IMLE(z_dim)\n",
    "\n",
    "# load previous model\n",
    "state_dict = torch.load(\"../checkpoint_single_channel_init_later.pth.tar\",\\\n",
    "                        map_location=torch.device('cpu'))\n",
    "imle.model.load_state_dict(state_dict)\n",
    "\n",
    "# test output\n",
    "z = torch.randn(batch_size, z_dim)\n",
    "print(imle(z).shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"../training_set_des.npy\")[::100,0:1,:,:]\n",
    "print(train_data.shape)\n",
    "\n",
    "plt.hist(train_data.flatten(), bins=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
