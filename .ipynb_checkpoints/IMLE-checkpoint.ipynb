{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# import packages\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from astropy.io import fits\n",
    "from scipy import interpolate\n",
    "\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define plot properties\n",
    "from cycler import cycler\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import rc\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def rgb(r,g,b):\n",
    "    return (float(r)/256.,float(g)/256.,float(b)/256.)\n",
    "\n",
    "cb2 = [rgb(31,120,180), rgb(255,127,0), rgb(51,160,44), rgb(227,26,28), \\\n",
    "       rgb(166,206,227), rgb(253,191,111), rgb(178,223,138), rgb(251,154,153)]\n",
    "\n",
    "rcParams['figure.figsize'] = (9,7.5)\n",
    "#rcParams['figure.dpi'] = 300\n",
    "\n",
    "rcParams['lines.linewidth'] = 1\n",
    "\n",
    "rcParams['axes.prop_cycle'] = cycler('color', cb2)\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['axes.grid'] = False\n",
    "\n",
    "rcParams['patch.facecolor'] = cb2[0]\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "\n",
    "rcParams['font.size'] = 23\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring H3 spectra.\n",
    "\n",
    "> Curating spectra (in .h5 format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore spectra catalog\n",
    "fcat = h5py.File('../H3_spectra.h5', 'r')\n",
    "\n",
    "# find all paths\n",
    "obj_paths = []\n",
    "for key1 in list(fcat.keys())[0:-1]:\n",
    "    for key2 in list(fcat[key1].keys()):\n",
    "        for key3 in list(fcat[key1+\"/\"+key2].keys()):\n",
    "            objs = list(fcat[key1+\"/\"+key2+\"/\"+key3+\"/v3.0\"].keys())\n",
    "            obj_paths.append([key1+\"/\"+key2+\"/\"+key3+\"/v3.0/\"+obj for obj in objs])\n",
    "\n",
    "obj_paths = np.array([item for sublist in obj_paths for item in sublist])\n",
    "obj_ids = np.array([x.split(\"/\")[-1] for x in obj_paths])\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "# read H3 catalog\n",
    "hdulist = fits.open('../H3_labels.fits')\n",
    "H3_id = hdulist[1].data['H3_ID'].astype(\"str\")\n",
    "SNR = hdulist[1].data['SNR']\n",
    "teff = hdulist[1].data['Teff']\n",
    "logg = hdulist[1].data['logg']\n",
    "feh = hdulist[1].data['FeH']\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "# initiate list\n",
    "rest_wave = []\n",
    "flux_spectra = []\n",
    "eflux_spectra = []\n",
    "err_array = [] \n",
    "H3_id_2 = []\n",
    "ind_choose = []\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# cross matching\n",
    "# the SNR in rcat is using only 5160A-5290A\n",
    "indx =0\n",
    "for i in range(H3_id.size):\n",
    "    ind = np.where(obj_ids == H3_id[i])[0]\n",
    "    if len(ind) > 0:\n",
    "        rest_wave.append(np.array(fcat[obj_paths[ind[0]]]['mod_wave_rest']))\n",
    "        err_array.append(np.nanmedian(np.array(fcat[obj_paths[ind[0]]]['obs_flux'])\\\n",
    "                                 /np.array(fcat[obj_paths[ind[0]]]['obs_eflux'])))\n",
    "        eflux_spectra.append(np.array(fcat[obj_paths[ind[0]]]['obs_eflux']))\n",
    "        flux_spectra.append(np.array(fcat[obj_paths[ind[0]]]['obs_flux']))\n",
    "        H3_id_2.append(H3_id[i])\n",
    "        ind_choose.append(i)\n",
    "        \n",
    "#-----------------------------------------------------------------------------------------\n",
    "# convert to numpy array\n",
    "rest_wave = np.array(rest_wave)\n",
    "err_array = np.array(err_array)\n",
    "flux_spectra = np.array(flux_spectra)\n",
    "eflux_spectra = np.array(eflux_spectra)\n",
    "H3_id_2 = np.array(H3_id_2)\n",
    "ind_choose = np.array(ind_choose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"../H3_spectra.npz\",\\\n",
    "         rest_wave = rest_wave,\\\n",
    "         err_array = err_array,\\\n",
    "         flux_spectra = flux_spectra,\\\n",
    "         eflux_spectra = eflux_spectra,\\\n",
    "         H3_id = H3_id[ind_choose],\n",
    "         SNR = SNR[ind_choose],\\\n",
    "         teff = teff[ind_choose],\\\n",
    "         logg = logg[ind_choose],\\\n",
    "         feh = feh[ind_choose],\\\n",
    "         h3_flag = h3_flag[ind_choose])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(SNR[ind_choose],err_array, s=1)\n",
    "plt.xlabel(\"rcat SNR\")\n",
    "plt.ylabel(\"Median (eflux / flux)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(SNR[ind_choose]-err_array, bins=100);\n",
    "plt.xlabel(\"rcat SNR - fcat SNR\")\n",
    "\n",
    "outlier_1 = np.where(SNR[ind_choose]-err_array > 20.)[0]\n",
    "print(H3_id_2[outlier_1][0])\n",
    "#outlier_2 = np.where(err_array-SNR[ind_choose] > 25.)[0]\n",
    "#print(H3_id_2[outlier_2][0])\n",
    "\n",
    "print(np.sum(np.abs(SNR[ind_choose]-err_array)/np.abs(SNR[ind_choose]+err_array)/2. > 0.05)/SNR[ind_choose].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> H3 spectra S/N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore labels\n",
    "hdulist = fits.open('../H3_labels.fits')\n",
    "H3_id = hdulist[1].data['H3_ID']\n",
    "SNR = hdulist[1].data['SNR']\n",
    "\n",
    "print(SNR.shape)\n",
    "print(np.sum(SNR > 10.))\n",
    "plt.hist(SNR, bins=100, cumulative=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Explore H3 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore labels\n",
    "hdulist = fits.open('../H3_labels.fits')\n",
    "H3_id = hdulist[1].data['H3_ID']\n",
    "SNR = hdulist[1].data['SNR']\n",
    "teff = hdulist[1].data['Teff']\n",
    "logg = hdulist[1].data['logg']\n",
    "feh = hdulist[1].data['FeH']\n",
    "\n",
    "\n",
    "#=====================================================================================\n",
    "# import packages\n",
    "import read_mist_models\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# initiate the plot\n",
    "fig = plt.figure(figsize=[10,9]);\n",
    "ax = fig.gca();\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(\"Teff [K]\", fontsize=30, labelpad=10);\n",
    "ax.set_ylabel(\"Log g\", fontsize=30, labelpad=10);\n",
    "\n",
    "# set range\n",
    "plt.xlim([3500,7000])\n",
    "plt.ylim([-0.5,5.])\n",
    "\n",
    "# invert axis\n",
    "plt.gca().invert_xaxis()\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# add padding\n",
    "ax.tick_params(axis='x', pad=10);\n",
    "\n",
    "# reduce number of ticks\n",
    "plt.locator_params(nbins=5)\n",
    "\n",
    "\n",
    "#=====================================================================================\n",
    "# plot results\n",
    "sc = plt.scatter(teff, logg, s=3, edgecolor=\"none\", cmap=plt.cm.get_cmap('jet'),\\\n",
    "                 c=feh, vmin=-2.00, vmax=0., rasterized=True)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# read mist models\n",
    "iso = read_mist_models.ISO('../isochrones_MIST/' \\\n",
    "                           + 'MIST_v1.1_feh_m2.00_afe_p0.0_vvcrit0.4_full.iso')\n",
    "\n",
    "# extract information\n",
    "age_ind = iso.age_index(np.log10(7*10**9))\n",
    "EEP = iso.isos[age_ind]['EEP']\n",
    "choose = (EEP > 202)*(EEP < 707)\n",
    "Teff_iso = 10.**iso.isos[age_ind]['log_Teff']\n",
    "logg_iso = iso.isos[age_ind]['log_g']\n",
    "        \n",
    "# plot isochrone\n",
    "plt.plot(Teff_iso[choose], logg_iso[choose], color=\"black\", lw=2, ls=\"--\", label=\"[Fe/H] = -0.50\")\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# read mist models\n",
    "iso = read_mist_models.ISO('../isochrones_MIST/' \\\n",
    "                           + 'MIST_v1.1_feh_m1.00_afe_p0.0_vvcrit0.4_full.iso')\n",
    "     \n",
    "# extract information\n",
    "age_ind = iso.age_index(np.log10(7*10**9))\n",
    "EEP = iso.isos[age_ind]['EEP']\n",
    "choose = (EEP > 202)*(EEP < 707)\n",
    "Teff_iso = 10.**iso.isos[age_ind]['log_Teff']\n",
    "logg_iso = iso.isos[age_ind]['log_g']\n",
    "        \n",
    "# plot isochrone\n",
    "plt.plot(Teff_iso[choose], logg_iso[choose], color=\"black\", lw=2, label=\"[Fe/H] = 0.00\")\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# read mist models\n",
    "iso = read_mist_models.ISO('../isochrones_MIST/' \\\n",
    "                           + 'MIST_v1.1_feh_p0.00_afe_p0.0_vvcrit0.4_full.iso')\n",
    "\n",
    "# extract information\n",
    "age_ind = iso.age_index(np.log10(10*10**9))\n",
    "EEP = iso.isos[age_ind]['EEP']\n",
    "choose = (EEP > 202)*(EEP < 707)\n",
    "Teff_iso = 10.**iso.isos[age_ind]['log_Teff']\n",
    "logg_iso = iso.isos[age_ind]['log_g']\n",
    "        \n",
    "# plot isochrone\n",
    "plt.plot(Teff_iso[choose], logg_iso[choose], color=\"black\", lw=2, ls=\":\", label=\"[Fe/H] = 0.50\")\n",
    "\n",
    "\n",
    "#=====================================================================================\n",
    "# save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../Fig7.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Explore H3 synthetic grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from phil_h3_smoothing import smoothspec\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# all the hdf5 files\n",
    "file_list = os.listdir(\"../H3_grid\")\n",
    "\n",
    "# loop over all files\n",
    "spectra = []\n",
    "parameters = []\n",
    "wavelength = []\n",
    "for file_name in file_list:\n",
    "    fcat = h5py.File('../H3_grid/' + file_name, 'r')\n",
    "    spectra.extend(np.array(fcat['spectra'])/np.array(fcat['continuua']))\n",
    "    wavelength = np.array(fcat['wavelengths'])\n",
    "    parameters_temp = np.array(fcat['parameters'])\n",
    "    parameters.extend(np.array([np.array(list(parameters_temp[i])) \\\n",
    "                                for i in range(len(parameters_temp))]))\n",
    "spectra = np.array(spectra)\n",
    "parameters = np.array(parameters)\n",
    "wavelength = np.array(wavelength)\n",
    "print(spectra.shape)\n",
    "print(parameters.shape)\n",
    "print(wavelength.shape)\n",
    "    \n",
    "#---------------------------------------------------------------------------------\n",
    "# convert log Teff to Teff\n",
    "parameters[:,0] = 10.**parameters[:,0] \n",
    "\n",
    "# restrict to Teff = 3500-10000, logg = 0-5\n",
    "ind = (parameters[:,0] >= 3500.)*(parameters[:,0] <= 10000.)\\\n",
    "       *(parameters[:,1] >= 0.)*(parameters[:,1] <= 5.)\n",
    "parameters = parameters[ind,:]\n",
    "spectra = spectra[ind,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wavelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define wavelength range\n",
    "waverange = [5100, 5350]\n",
    "\n",
    "# define output wavleength\n",
    "wavelength_i = np.copy(wavelength)\n",
    "wavelength_o = []\n",
    "resolution_o = 100000\n",
    "resolution = resolution_o/2.355\n",
    "\n",
    "i = 1\n",
    "while True:\n",
    "    wave_i = waverange[0]*(1.0 + 1.0/(3.0*resolution))**(i-1.0)\n",
    "    if wave_i <= waverange[1]:\n",
    "        wavelength_o.append(wave_i)\n",
    "        i += 1\n",
    "    else:\n",
    "        break\n",
    "wavelength_o = np.array(wavelength_o)\n",
    "        \n",
    "# smooth the spectra\n",
    "spectra_o = []\n",
    "for i in range(spectra.shape[0]):\n",
    "    spectra_o.append(smoothspec(wavelength_i,spectra[i,:], resolution_o,\\\n",
    "                                outwave=wavelength_o, smoothtype='R', fftsmooth=True, inres=500000.0))\n",
    "spectra = np.copy(spectra_o)\n",
    "\n",
    "np.savez(\"../H3_training_grid.npz\",\\\n",
    "         labels = parameters,\\\n",
    "         spectra = spectra,\\\n",
    "         wavelength = wavelength_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wavelength_o)\n",
    "print(wavelength_o.shape)\n",
    "print(spectra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(spectra[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral emulation with IMLE / autoregressive flow.\n",
    "\n",
    "> Plot the training losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_err_array = []\n",
    "for i in range(30):\n",
    "    temp = np.load(\"../mse_err_deconv_256x2_\" + str((i+1)*100-1) +  \".npz\")\n",
    "    mse_err_array.append(temp[\"mse_err\"])\n",
    "mse_err_array = np.array(mse_err_array)\n",
    "\n",
    "fig = plt.figure(figsize=[10.,8.])\n",
    "ax = fig.gca();\n",
    "ax.set_yscale('log')\n",
    "plt.plot(mse_err_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Payne training loss\n",
    "temp = np.load(\"../training_loss_payne.npz\")\n",
    "training_loss = temp[\"training_loss\"]\n",
    "validation_loss = temp[\"validation_loss\"]\n",
    "plt.plot(training_loss)\n",
    "plt.plot(validation_loss)\n",
    "plt.ylim({10,100})\n",
    "plt.yscale('log')\n",
    "\n",
    "temp = np.load(\"../training_loss_resnet.npz\")\n",
    "training_loss = temp[\"training_loss\"]\n",
    "validation_loss = temp[\"validation_loss\"]\n",
    "plt.plot(training_loss)\n",
    "plt.plot(validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Prediction uncertainty (Kurucz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore wavelength\n",
    "temp = np.load(\"../apogee_windows.npz\")\n",
    "wavelength_template = temp[\"filter_wavelength\"]\n",
    "# wavelength_template = temp[\"filter_wavelength\"][:7163]\n",
    "\n",
    "# restore results\n",
    "# temp = np.load(\"../results_spectra_deconv_256x2_2999.npz\")\n",
    "# Y_u_all = temp[\"data_np\"].T\n",
    "# predict_flux_array = temp[\"samples_np\"].T\n",
    "\n",
    "# predict_flux_array = np.load(\"../predict_flux_array.npy\").T\n",
    "# print(predict_flux_array.shape)\n",
    "\n",
    "# temp = np.load(\"../ind_shuffle_kurucz.npz\")\n",
    "# ind_shuffle = temp[\"ind_shuffle\"]\n",
    "# print(ind_shuffle.shape)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# restore training set\n",
    "# temp = np.load(\"../mock_all_spectra_no_noise_resample_prior_large.npz\")\n",
    "# labels_array = temp[\"labels\"][:,:Y_u_all.shape[1]]\n",
    "\n",
    "# labels_array = temp[\"labels\"][:,ind_shuffle][:,12000:14100]\n",
    "# Y_u_all = temp[\"spectra\"].T[:7163,:][:,ind_shuffle][:,12000:14100]\n",
    "# print(Y_u_all.shape)\n",
    "\n",
    "# calculate flux deviation\n",
    "flux_deviate = np.median(np.abs(Y_u_all - predict_flux_array),axis=1)\n",
    "max_deviate = np.percentile(np.abs(Y_u_all - predict_flux_array),95,axis=1)\n",
    "median_deviate = np.median(np.abs(Y_u_all - predict_flux_array),axis=0)\n",
    "\n",
    "\n",
    "#===============================================================================================\n",
    "# initiate the plot\n",
    "fig = plt.figure(figsize=[22,15]);\n",
    "\n",
    "# combine labels\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.tick_params(labelcolor='w', top=0, bottom=0, left=0, right=0)\n",
    "\n",
    "\n",
    "#===============================================================================================\n",
    "# plot results\n",
    "ax = plt.subplot2grid((2,2), (0,0))\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(r\"Wavelength [A]\");\n",
    "ax.set_ylabel(r\"Normalized flux + shift\");\n",
    "\n",
    "ax.tick_params(axis='x', pad=15);\n",
    "\n",
    "# set the range\n",
    "plt.xlim([15200,15300])\n",
    "plt.ylim([0.3,1.1])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# plot results\n",
    "ind_plot = 54\n",
    "ind_standard = 4\n",
    "\n",
    "plt.plot(wavelength_template, Y_u_all[:,ind_standard],\\\n",
    "         color=cb2[3], lw=2, label=\"Ab initio model spectrum\")\n",
    "plt.plot(wavelength_template, predict_flux_array[:,ind_standard],\\\n",
    "         color=\"black\", ls=\"--\", lw=2, label=\"The Payne approximation\")\n",
    "\n",
    "plt.plot(wavelength_template, Y_u_all[:,ind_plot] - 0.3,\\\n",
    "         color=cb2[3], lw=2)\n",
    "plt.plot(wavelength_template, predict_flux_array[:,ind_plot] - 0.3,\\\n",
    "         color=\"black\", ls=\"--\", lw=2)\n",
    "\n",
    "# add legend\n",
    "plt.legend(loc=\"lower right\", fontsize=25, frameon=False,\\\n",
    "            borderpad=0.1, labelspacing=0.5)\n",
    "    \n",
    "\n",
    "#===============================================================================================\n",
    "# plot results\n",
    "ax = plt.subplot2grid((2,2), (1,0))\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(r\"Wavelength [A]\");\n",
    "ax.set_ylabel(r\"Median approximation error\");\n",
    "\n",
    "ax.tick_params(axis='x', pad=15);\n",
    "\n",
    "# set the range\n",
    "plt.xlim([15200,15300])\n",
    "plt.ylim([10**-4,10**-2])\n",
    "\n",
    "# plot in log scale\n",
    "ax.set_yscale('log');\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# plot results\n",
    "flux_deviate_part = np.median(np.abs(Y_u_all-predict_flux_array),axis=1)\n",
    "plt.plot(wavelength_template, flux_deviate_part, color=\"black\", lw=2)\n",
    "\n",
    "\n",
    "#===============================================================================================\n",
    "# plot results\n",
    "ax = plt.subplot2grid((2,2), (0,1))\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(r\"(Wavelength) Median approximation error of The Payne\");\n",
    "ax.set_ylabel(r\"# Cross validation models\");\n",
    "\n",
    "ax.tick_params(axis='x', pad=15);\n",
    "\n",
    "# set the range\n",
    "plt.xlim([-4,-1.])\n",
    "plt.ylim([0,220])\n",
    "#plt.ylim([0,1200])\n",
    "\n",
    "# set the range\n",
    "plt.xticks([-4,-3,-2,-1],\\\n",
    "           [\"$\\mathregular{10^{-4}}$\", \"$\\mathregular{10^{-3}}$\",\\\n",
    "            \"$\\mathregular{10^{-2}}$\", \"$\\mathregular{10^{-1}}$\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# plot result\n",
    "choose = (labels_array[0,:] > 3500.)*(labels_array[0,:] < 4500.)\n",
    "plt.hist(np.log10(median_deviate)[choose],\\\n",
    "         histtype=\"step\", bins=20, color=cb2[0], lw=3)\n",
    "\n",
    "choose = (labels_array[0,:] > 4500.)*(labels_array[0,:] < 6000.)\n",
    "plt.hist(np.log10(median_deviate)[choose],\\\n",
    "         histtype=\"step\", bins=20, color=cb2[3], lw=3)\n",
    "\n",
    "choose = (labels_array[0,:] > 6000.)*(labels_array[0,:] < 8000.)\n",
    "plt.hist(np.log10(median_deviate)[choose],\\\n",
    "         histtype=\"step\", bins=20, color=\"black\", lw=3)\n",
    "\n",
    "# add legend\n",
    "plt.plot([-999,-999.1],[-999,-999.1], color=cb2[0], lw=3,\\\n",
    "         label=r\"$\\mathregular{T_{\\rm eff} = 3000K - 4500K}$\")\n",
    "plt.plot([-999,-999.1],[-999,-999.1], color=cb2[3], lw=3,\\\n",
    "         label=r\"$\\mathregular{T_{\\rm eff} = 4500K - 6000K}$\")\n",
    "plt.plot([-999,-999.1],[-999,-999.1], color=\"black\", lw=3,\\\n",
    "          label=r\"$\\mathregular{T_{\\rm eff} = 6000K - 8000K}$\")\n",
    "\n",
    "plt.legend(loc=\"upper right\", fontsize=25, frameon=False,\\\n",
    "            borderpad=0.5, labelspacing=0.5)\n",
    "\n",
    "\n",
    "#===============================================================================================\n",
    "# plot results\n",
    "ax = plt.subplot2grid((2,2), (1,1))\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(r\"(Spectrum) Median approximation error of The Payne\");\n",
    "ax.set_ylabel(r\"Cumulative # wavelength pixels [%]\");\n",
    "\n",
    "ax.tick_params(axis='x', pad=15);\n",
    "\n",
    "# set the range\n",
    "plt.xlim([10**-4,10**-0.9])\n",
    "plt.ylim([0.,1.0])\n",
    "\n",
    "ax.set_xscale('log');\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# add end points\n",
    "flux_deviate = np.concatenate([flux_deviate,[1.]])\n",
    "max_deviate = np.concatenate([max_deviate,[1.]])\n",
    "\n",
    "# plot result\n",
    "plt.hist(flux_deviate,\\\n",
    "         histtype=\"step\", cumulative=True, normed=True,\\\n",
    "         bins=10000000, lw=2, color=\"black\")\n",
    "plt.hist(max_deviate,\\\n",
    "         histtype=\"step\", cumulative=True, normed=True,\\\n",
    "         bins=10000000, lw=2, color=\"black\", ls=\":\")\n",
    "\n",
    "# add legend\n",
    "l3, = plt.plot([-999,-999.1],[-999,-999.1], color=\"black\", lw=2, ls=\"-\", label=\"Median\")\n",
    "l4, = plt.plot([-999,-999.1],[-999,-999.1], color=\"black\", lw=2, ls=\":\", label=r\"$\\mathregular{2\\sigma}$\")\n",
    "\n",
    "plt.legend(loc=\"upper left\",\\\n",
    "           fontsize=25, frameon=False, borderpad=0.5, labelspacing=0.5)\n",
    "\n",
    "\n",
    "#===============================================================================================\n",
    "# save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../Fig4.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make Payne predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import The Payne github\n",
    "from The_Payne import spectral_model\n",
    "\n",
    "# restore array\n",
    "tmp = np.load(\"../NN_normalized_spectra_payne.npz\")\n",
    "w_array_0 = tmp[\"w_array_0\"]\n",
    "w_array_1 = tmp[\"w_array_1\"]\n",
    "w_array_2 = tmp[\"w_array_2\"]\n",
    "b_array_0 = tmp[\"b_array_0\"]\n",
    "b_array_1 = tmp[\"b_array_1\"]\n",
    "b_array_2 = tmp[\"b_array_2\"]\n",
    "x_min = tmp[\"x_min\"]\n",
    "x_max = tmp[\"x_max\"]\n",
    "\n",
    "tmp.close()\n",
    "NN_coeffs = (w_array_0, w_array_1, w_array_2, b_array_0, b_array_1, b_array_2, x_min, x_max)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "# read spectra\n",
    "temp = np.load(\"../H3_training_grid.npz\")\n",
    "labels = temp[\"labels\"]\n",
    "labels[:,0] = labels[:,0]/1000.\n",
    "Y_u_all = temp[\"spectra\"].T\n",
    "\n",
    "# calculate spectrum\n",
    "predict_flux_array = []\n",
    "\n",
    "for i in range(labels.shape[0]):\n",
    "    label_test = (labels[i,:]-x_min)/(x_max-x_min) - 0.5\n",
    "    predict_flux_array.append(spectral_model.get_spectrum_from_neural_net(scaled_labels = label_test,\\\n",
    "                                                       NN_coeffs = NN_coeffs))\n",
    "\n",
    "predict_flux_array = np.array(predict_flux_array).T\n",
    "print(predict_flux_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Prediction uncertainty (for H3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore results\n",
    "#predict_flux_array = np.load(\"../predict_flux_array.npy\").T\n",
    "\n",
    "# load training set\n",
    "temp = np.load(\"../H3_training_grid.npz\")\n",
    "labels_array = temp[\"labels\"].T\n",
    "Y_u_all = temp[\"spectra\"].T\n",
    "wavelength_template = temp[\"wavelength\"]\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# restrict to only the validation set\n",
    "temp = np.load(\"../ind_shuffle_payne_h3.npz\")\n",
    "ind_shuffle = temp[\"ind_shuffle\"]\n",
    "Y_u_all = Y_u_all[:,ind_shuffle][:,18000:]\n",
    "predict_flux_array = predict_flux_array[:,ind_shuffle][:,18000:]\n",
    "labels_array = labels_array[:,ind_shuffle][:,18000:]\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# calculate flux deviation\n",
    "flux_deviate = np.median(np.abs(Y_u_all - predict_flux_array),axis=1)\n",
    "max_deviate = np.percentile(np.abs(Y_u_all - predict_flux_array),95,axis=1)\n",
    "median_deviate = np.median(np.abs(Y_u_all - predict_flux_array),axis=0)\n",
    "\n",
    "\n",
    "#===============================================================================================\n",
    "# initiate the plot\n",
    "fig = plt.figure(figsize=[22,15]);\n",
    "\n",
    "# combine labels\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.tick_params(labelcolor='w', top=0, bottom=0, left=0, right=0)\n",
    "\n",
    "\n",
    "#===============================================================================================\n",
    "# plot results\n",
    "# ax = plt.subplot2grid((2,2), (0,0))\n",
    "\n",
    "# # axis labels\n",
    "# ax.set_xlabel(r\"Wavelength [A]\");\n",
    "# ax.set_ylabel(r\"Normalized flux + shift\");\n",
    "\n",
    "# ax.tick_params(axis='x', pad=15);\n",
    "\n",
    "# # set the range\n",
    "# plt.xlim([5200,5220])\n",
    "# plt.ylim([0.1,1.1])\n",
    "\n",
    "# #-------------------------------------------------------------------------------------------------\n",
    "# # plot results\n",
    "# ind_plot = 54\n",
    "# ind_standard = 5\n",
    "\n",
    "# plt.plot(wavelength_template, Y_u_all[:,ind_standard],\\\n",
    "#          color=cb2[3], lw=2, label=\"Ab initio model spectrum\")\n",
    "# plt.plot(wavelength_template, predict_flux_array[:,ind_standard],\\\n",
    "#          color=\"black\", ls=\"--\", lw=2, label=\"The Payne approximation\")\n",
    "\n",
    "# plt.plot(wavelength_template, Y_u_all[:,ind_plot] - 0.3,\\\n",
    "#          color=cb2[3], lw=2)\n",
    "# plt.plot(wavelength_template, predict_flux_array[:,ind_plot] - 0.3,\\\n",
    "#          color=\"black\", ls=\"--\", lw=2)\n",
    "\n",
    "# # add legend\n",
    "# plt.legend(loc=\"lower right\", fontsize=25, frameon=False,\\\n",
    "#             borderpad=0.1, labelspacing=0.5)\n",
    "    \n",
    "\n",
    "#===============================================================================================\n",
    "# plot results\n",
    "ax = plt.subplot2grid((2,2), (1,0))\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(r\"Wavelength [A]\");\n",
    "ax.set_ylabel(r\"Median approximation error\");\n",
    "\n",
    "ax.tick_params(axis='x', pad=15);\n",
    "\n",
    "# set the range\n",
    "plt.xlim([5200,5220])\n",
    "plt.ylim([10**-4,10**-2])\n",
    "\n",
    "# plot in log scale\n",
    "ax.set_yscale('log');\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# plot results\n",
    "flux_deviate_part = np.median(np.abs(Y_u_all-predict_flux_array),axis=1)\n",
    "plt.plot(wavelength_template, flux_deviate_part, color=\"black\", lw=2)\n",
    "\n",
    "\n",
    "#===============================================================================================\n",
    "# plot results\n",
    "ax = plt.subplot2grid((2,2), (0,1))\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(r\"(Wavelength) Median approximation error of The Payne\");\n",
    "ax.set_ylabel(r\"# Cross validation models\");\n",
    "\n",
    "ax.tick_params(axis='x', pad=15);\n",
    "\n",
    "# set the range\n",
    "plt.xlim([-4,-1.])\n",
    "#plt.ylim([0,1000])\n",
    "plt.ylim([0,100])\n",
    "\n",
    "# set the range\n",
    "plt.xticks([-4,-3,-2,-1],\\\n",
    "           [\"$\\mathregular{10^{-4}}$\", \"$\\mathregular{10^{-3}}$\",\\\n",
    "            \"$\\mathregular{10^{-2}}$\", \"$\\mathregular{10^{-1}}$\"])\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# plot result\n",
    "print(labels_array.shape)\n",
    "choose = (labels_array[0,:] > 3500.)*(labels_array[0,:] < 4500.)\n",
    "print(choose.shape)\n",
    "plt.hist(np.log10(median_deviate)[choose],\\\n",
    "         histtype=\"step\", bins=20, color=cb2[0], lw=3)\n",
    "\n",
    "choose = (labels_array[0,:] > 4500.)*(labels_array[0,:] < 7000.)\n",
    "plt.hist(np.log10(median_deviate)[choose],\\\n",
    "         histtype=\"step\", bins=20, color=cb2[3], lw=3)\n",
    "\n",
    "choose = (labels_array[0,:] > 7000.)*(labels_array[0,:] < 10000.)\n",
    "plt.hist(np.log10(median_deviate)[choose],\\\n",
    "         histtype=\"step\", bins=20, color=\"black\", lw=3)\n",
    "\n",
    "# add legend\n",
    "plt.plot([-999,-999.1],[-999,-999.1], color=cb2[0], lw=3,\\\n",
    "         label=r\"$\\mathregular{T_{\\rm eff} = 3500K - 4500K}$\")\n",
    "plt.plot([-999,-999.1],[-999,-999.1], color=cb2[3], lw=3,\\\n",
    "         label=r\"$\\mathregular{T_{\\rm eff} = 4500K - 7000K}$\")\n",
    "plt.plot([-999,-999.1],[-999,-999.1], color=\"black\", lw=3,\\\n",
    "          label=r\"$\\mathregular{T_{\\rm eff} = 7000K - 10000K}$\")\n",
    "\n",
    "plt.legend(loc=\"upper right\", fontsize=25, frameon=False,\\\n",
    "            borderpad=0.5, labelspacing=0.5)\n",
    "\n",
    "\n",
    "#===============================================================================================\n",
    "# plot results\n",
    "ax = plt.subplot2grid((2,2), (1,1))\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(r\"(Spectrum) Median approximation error of The Payne\");\n",
    "ax.set_ylabel(r\"Cumulative # wavelength pixels [%]\");\n",
    "\n",
    "ax.tick_params(axis='x', pad=15);\n",
    "\n",
    "# set the range\n",
    "plt.xlim([10**-4,10**-0.9])\n",
    "plt.ylim([0.,1.0])\n",
    "\n",
    "ax.set_xscale('log');\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# add end points\n",
    "flux_deviate = np.concatenate([flux_deviate,[1.]])\n",
    "max_deviate = np.concatenate([max_deviate,[1.]])\n",
    "\n",
    "# plot result\n",
    "plt.hist(flux_deviate,\\\n",
    "         histtype=\"step\", cumulative=True, normed=True,\\\n",
    "         bins=10000000, lw=2, color=\"black\")\n",
    "plt.hist(max_deviate,\\\n",
    "         histtype=\"step\", cumulative=True, normed=True,\\\n",
    "         bins=10000000, lw=2, color=\"black\", ls=\":\")\n",
    "\n",
    "# add legend\n",
    "l3, = plt.plot([-999,-999.1],[-999,-999.1], color=\"black\", lw=2, ls=\"-\", label=\"Median\")\n",
    "l4, = plt.plot([-999,-999.1],[-999,-999.1], color=\"black\", lw=2, ls=\":\", label=r\"$\\mathregular{2\\sigma}$\")\n",
    "\n",
    "plt.legend(loc=\"lower right\",\\\n",
    "           fontsize=25, frameon=False, borderpad=0.5, labelspacing=0.5)\n",
    "\n",
    "\n",
    "#===============================================================================================\n",
    "# plot results\n",
    "ax = plt.subplot2grid((2,2), (0,0))\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(r\"Pixel-by-pixel approximation error of The Payne\");\n",
    "ax.set_ylabel(r\"Cumulative # wavelength pixels [%]\");\n",
    "\n",
    "ax.tick_params(axis='x', pad=15);\n",
    "\n",
    "# set the range\n",
    "plt.xlim([10**-5,10**-1.9])\n",
    "plt.ylim([0.,1.0])\n",
    "\n",
    "ax.set_xscale('log');\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# add end points\n",
    "flux_deviate = np.concatenate([flux_deviate,[1.]])\n",
    "max_deviate = np.concatenate([max_deviate,[1.]])\n",
    "\n",
    "# plot result\n",
    "choose = (labels_array[0,:] > 3500.)*(labels_array[0,:] < 4500.)\n",
    "plt.hist(np.abs(Y_u_all[:,choose]-predict_flux_array[:,choose]).ravel(),\\\n",
    "         histtype=\"step\", cumulative=True, normed=True,\\\n",
    "         bins=10000000, lw=2, color=cb2[0])\n",
    "\n",
    "choose = (labels_array[0,:] > 4500.)*(labels_array[0,:] < 7000.)\n",
    "plt.hist(np.abs(Y_u_all[:,choose]-predict_flux_array[:,choose]).ravel(),\\\n",
    "         histtype=\"step\", cumulative=True, normed=True,\\\n",
    "         bins=10000000, lw=2, color=cb2[3])\n",
    "\n",
    "choose = (labels_array[0,:] > 7000.)*(labels_array[0,:] < 10000.)\n",
    "plt.hist(np.abs(Y_u_all[:,choose]-predict_flux_array[:,choose]).ravel(),\\\n",
    "         histtype=\"step\", cumulative=True, normed=True,\\\n",
    "         bins=10000000, lw=2, color=\"black\")\n",
    "\n",
    "# add legend\n",
    "plt.plot([-999,-999.1],[-999,-999.1], color=cb2[0], lw=3,\\\n",
    "         label=r\"$\\mathregular{T_{\\rm eff} = 3500K - 4500K}$\")\n",
    "plt.plot([-999,-999.1],[-999,-999.1], color=cb2[3], lw=3,\\\n",
    "         label=r\"$\\mathregular{T_{\\rm eff} = 4500K - 7000K}$\")\n",
    "plt.plot([-999,-999.1],[-999,-999.1], color=\"black\", lw=3,\\\n",
    "          label=r\"$\\mathregular{T_{\\rm eff} = 7000K - 10000K}$\")\n",
    "\n",
    "plt.legend(loc=\"upper left\", fontsize=25, frameon=False,\\\n",
    "            borderpad=0.5, labelspacing=0.5)\n",
    "\n",
    "\n",
    "#===============================================================================================\n",
    "# save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../Fig4.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to only the validation set\n",
    "np.savez(\"H3_emulator_payne.npz\",\\\n",
    "         true_spectra = Y_u_all.T,\\\n",
    "         emulator_prediction = predict_flux_array.T,\\\n",
    "         labels = labels_array.T,\\\n",
    "         wavelength = wavelength_template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "#=============================================================================================================\n",
    "# define network\n",
    "class ConvolutionalImplicitModel(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super( ConvolutionalImplicitModel, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        layers = []\n",
    "        channel = 32\n",
    "\n",
    "        for i in range(6):\n",
    "            for j in range(2):\n",
    "\n",
    "                if i == 0 and j == 0:\n",
    "                    layers.append(torch.nn.ConvTranspose1d(z_dim, channel, 6, stride=1))\n",
    "                    layers.append(torch.nn.BatchNorm1d(channel, momentum=0.001, affine=False))\n",
    "                    layers.append(torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "                else:\n",
    "                    layers.append(torch.nn.Conv1d(channel, channel, 6, stride=1, padding=2))\n",
    "                    layers.append(torch.nn.BatchNorm1d(channel, momentum=0.001, affine=False))\n",
    "                    layers.append(torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "            if i < 5:\n",
    "                layers.append(torch.nn.Upsample(scale_factor=4, mode='linear', align_corners = False))\n",
    "            else:\n",
    "                layers.append(torch.nn.Conv1d(channel, 1, 6, stride=1))\n",
    "                layers.append(torch.nn.LeakyReLU())\n",
    "\n",
    "        self.model = torch.nn.Sequential(*layers)\n",
    "        self.add_module(\"model\", self.model)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "    \n",
    "\n",
    "#=============================================================================================================\n",
    "# restore data\n",
    "model = ConvolutionalImplicitModel(29)\n",
    "x = torch.zeros((100,29,1))\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "#=============================================================================================================\n",
    "# resnet models\n",
    "class Payne_model(torch.nn.Module):\n",
    "    def __init__(self, dim_in, num_neurons, num_features, mask_size, num_pixel):\n",
    "        super(Payne_model, self).__init__()\n",
    "        self.features = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim_in, num_neurons),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(num_neurons, num_neurons),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(num_neurons, num_features),\n",
    "        )\n",
    "\n",
    "        self.deconv1 = torch.nn.ConvTranspose1d(64, 64, mask_size, stride=3, padding=5)\n",
    "        self.deconv2 = torch.nn.ConvTranspose1d(64, 64, mask_size, stride=3, padding=5)\n",
    "        self.deconv3 = torch.nn.ConvTranspose1d(64, 64, mask_size, stride=3, padding=5)\n",
    "        self.deconv4 = torch.nn.ConvTranspose1d(64, 64, mask_size, stride=3, padding=5)\n",
    "        self.deconv5 = torch.nn.ConvTranspose1d(64, 64, mask_size, stride=3, padding=5)\n",
    "        self.deconv6 = torch.nn.ConvTranspose1d(64, 32, mask_size, stride=3, padding=5)\n",
    "        self.deconv7 = torch.nn.ConvTranspose1d(32, 1, mask_size, stride=3, padding=5)\n",
    "\n",
    "        self.deconv2b = torch.nn.ConvTranspose1d(64, 64, 1, stride=3)\n",
    "        self.deconv3b = torch.nn.ConvTranspose1d(64, 64, 1, stride=3)\n",
    "        self.deconv4b = torch.nn.ConvTranspose1d(64, 64, 1, stride=3)\n",
    "        self.deconv5b = torch.nn.ConvTranspose1d(64, 64, 1, stride=3)\n",
    "        self.deconv6b = torch.nn.ConvTranspose1d(64, 32, 1, stride=3)\n",
    "\n",
    "        self.relu2 = torch.nn.LeakyReLU()\n",
    "        self.relu3 = torch.nn.LeakyReLU()\n",
    "        self.relu4 = torch.nn.LeakyReLU()\n",
    "        self.relu5 = torch.nn.LeakyReLU()\n",
    "        self.relu6 = torch.nn.LeakyReLU()\n",
    "\n",
    "        self.num_pixel = num_pixel\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)[:,None,:]\n",
    "        x = x.view(x.shape[0], 64, 3)\n",
    "        x1 = self.deconv1(x)\n",
    "\n",
    "        x2 = self.deconv2(x1)\n",
    "        x2 += self.deconv2b(x1)\n",
    "        x2 = self.relu2(x2)\n",
    "\n",
    "        x3 = self.deconv3(x2)\n",
    "        x3 += self.deconv3b(x2)\n",
    "        x3 = self.relu2(x3)\n",
    "\n",
    "        x4 = self.deconv4(x3)\n",
    "        x4 += self.deconv4b(x3)\n",
    "        x4 = self.relu2(x4)\n",
    "\n",
    "        x5 = self.deconv5(x4)\n",
    "        x5 += self.deconv5b(x4)\n",
    "        x5 = self.relu2(x5)\n",
    "\n",
    "        x6 = self.deconv6(x5)\n",
    "        x6 += self.deconv6b(x5)\n",
    "        x6 = self.relu2(x6)\n",
    "\n",
    "        x7 = self.deconv7(x6)[:,0,:self.num_pixel]\n",
    "        return x7\n",
    "    \n",
    "\n",
    "#=============================================================================================================\n",
    "# restore data\n",
    "model = Payne_model(dim_in = 4, num_neurons = 300,\\\n",
    "                    num_features = 64*3, mask_size=11, num_pixel=4375)\n",
    "x = torch.zeros((100,4))\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_pixel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-030f0697f1e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     num_features = 64*3, mask_size=11, num_pixel=6097)\n\u001b[1;32m     47\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-030f0697f1e3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_pixel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_pixel' is not defined"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "#=============================================================================================================\n",
    "# define network\n",
    "class Payne_model(nn.Module):\n",
    "    def __init__(self, dim_in, num_neurons, num_features, mask_size, num_pixel):\n",
    "        super(Payne_model, self).__init__()\n",
    "        layers = []\n",
    "        channel = 256\n",
    "\n",
    "        for i in range(6):\n",
    "            for j in range(2):\n",
    "\n",
    "                if i == 0 and j == 0:\n",
    "                    layers.append(torch.nn.ConvTranspose1d(dim_in, channel, 7, stride=1))\n",
    "                    layers.append(torch.nn.BatchNorm1d(channel, momentum=0.001, affine=False))\n",
    "                    layers.append(torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "                else:\n",
    "                    layers.append(torch.nn.Conv1d(channel, channel, 5, stride=1, padding=2))\n",
    "                    layers.append(torch.nn.BatchNorm1d(channel, momentum=0.001, affine=False))\n",
    "                    layers.append(torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "            if i < 5:\n",
    "                layers.append(torch.nn.Upsample(scale_factor=4, mode='linear', align_corners = False))\n",
    "            else:\n",
    "                layers.append(torch.nn.Conv1d(channel, 1, 6, stride=1))\n",
    "                layers.append(torch.nn.LeakyReLU())\n",
    "\n",
    "        self.model = torch.nn.Sequential(*layers)\n",
    "        self.add_module(\"model\", self.model)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z[:,:,None]).view(-1,6097)\n",
    "    \n",
    "\n",
    "#=============================================================================================================\n",
    "# restore data\n",
    "model = Payne_model(dim_in = 4, num_neurons = 300,\\\n",
    "                    num_features = 64*3, mask_size=11, num_pixel=6097)\n",
    "x = torch.zeros((100,4))\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.load(\"../H3_training_grid.npz\")\n",
    "print(temp[\"wavelength\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral anomaly.\n",
    "\n",
    "> Check training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.load(\"../loss_results_lr=-4_SNR=20.npz\")\n",
    "loss_array = temp[\"loss_array\"]\n",
    "plt.plot(loss_array)\n",
    "plt.ylim([-6000,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sample log probablity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    "#========================================================================================================\n",
    "# restore data\n",
    "temp = np.load(\"../H3_spectra.npz\")\n",
    "h3_flag = temp[\"h3_flag\"]\n",
    "flux_spectra = temp[\"flux_spectra\"]\n",
    "err_array = temp[\"err_array\"]\n",
    "rest_wave = temp[\"rest_wave\"]\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "# define a uniform wavelength grid\n",
    "uniform_wave = np.linspace(5162,5290,flux_spectra.shape[1])\n",
    "\n",
    "# interpolate to the rest frame\n",
    "for i in range(flux_spectra.shape[0]):\n",
    "    if np.median(flux_spectra[i]) != 0:\n",
    "        f_flux_spec = interpolate.interp1d(rest_wave[i,:], flux_spectra[i,:])\n",
    "        flux_spectra[i,:] = f_flux_spec(uniform_wave)\n",
    "\n",
    "# cull empty spectra\n",
    "ind = np.where((np.median(flux_spectra, axis=1) != 0)*(err_array > 20.))[0]\n",
    "#ind = np.where((np.median(flux_spectra, axis=1) != 0)*(err_array > 20.)*(h3_flag == 0) == 1)[0]\n",
    "flux_spectra = flux_spectra[ind,:]\n",
    "print(flux_spectra.shape)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "# normalize spectra\n",
    "y_tr = (flux_spectra.T/np.median(flux_spectra, axis=1)).T\n",
    "\n",
    "# exclude bad pixels\n",
    "y_tr[np.isnan(y_tr)] = 1.\n",
    "y_tr[y_tr < 0.] = 0.\n",
    "y_tr[y_tr > 2] = 2.\n",
    "print(y_tr.shape)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "# convert into torch\n",
    "y_tr = torch.from_numpy(y_tr).type(torch.FloatTensor)\n",
    "\n",
    "# input dimension\n",
    "dim_in = y_tr.shape[-1]\n",
    "\n",
    "\n",
    "#=======================================================================================================\n",
    "# In [2]:\n",
    "# define normalizing flow\n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, nets, nett, mask, prior):\n",
    "        super(RealNVP, self).__init__()\n",
    "\n",
    "        self.prior = prior\n",
    "        self.mask = nn.Parameter(mask, requires_grad=False)\n",
    "        self.t = torch.nn.ModuleList([nett() for _ in range(len(masks))])\n",
    "        self.s = torch.nn.ModuleList([nets() for _ in range(len(masks))])\n",
    "\n",
    "    def g(self, z):\n",
    "        x = z\n",
    "        for i in range(len(self.t)):\n",
    "            x_ = x*self.mask[i]\n",
    "            s = self.s[i](x_)*(1 - self.mask[i])\n",
    "            t = self.t[i](x_)*(1 - self.mask[i])\n",
    "            x = x_ + (1 - self.mask[i]) * (x * torch.exp(s) + t)\n",
    "        return x\n",
    "\n",
    "    def f(self, x):\n",
    "        log_det_J, z = x.new_zeros(x.shape[0]), x\n",
    "        for i in reversed(range(len(self.t))):\n",
    "            z_ = self.mask[i] * z\n",
    "            s = self.s[i](z_) * (1-self.mask[i])\n",
    "            t = self.t[i](z_) * (1-self.mask[i])\n",
    "            z = (1 - self.mask[i]) * (z - t) * torch.exp(-s) + z_\n",
    "            log_det_J -= s.sum(dim=1)\n",
    "        return z, log_det_J\n",
    "\n",
    "    def log_prob(self,x):\n",
    "        z, logp = self.f(x)\n",
    "        return self.prior.log_prob(z) + logp\n",
    "\n",
    "    def sample(self, z):\n",
    "        x = self.g(z)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "#==================================================================================\n",
    "# restore models\n",
    "flow = torch.load(\"../flow_final_lr=-4_SNR=20.pt\", map_location=lambda storage, loc: storage) # load in cpu\n",
    "flow.eval()\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "# sample results\n",
    "log_prob_x = flow.log_prob(y_tr).detach().numpy()\n",
    "\n",
    "# save results\n",
    "np.savez(\"../real_nvp_results_h3.npz\",\\\n",
    "         ind = ind,\\\n",
    "         log_prob_x = log_prob_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot log probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore results\n",
    "temp = np.load(\"../real_nvp_results_h3.npz\")\n",
    "log_prob_x = temp[\"log_prob_x\"]\n",
    "ind = temp[\"ind\"]\n",
    "print(log_prob_x.shape)\n",
    "\n",
    "temp = np.load(\"../H3_spectra.npz\")\n",
    "h3_flag = temp[\"h3_flag\"][ind]\n",
    "\n",
    "#plt.hist(log_prob_x,bins=100, range=[-2000,7000], alpha=0.5);\n",
    "\n",
    "plt.hist(log_prob_x[h3_flag == 0], bins=100, alpha=0.5, normed=True);\n",
    "plt.hist(log_prob_x[h3_flag != 0], bins=100, alpha=0.5, normed=True);\n",
    "#print(log_prob_x[h3_flag != 0])\n",
    "print(np.sum(log_prob_x[h3_flag != 0] < np.min(log_prob_x[h3_flag == 0]))/np.sum(h3_flag != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Explore outliers in Kiel diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore results\n",
    "temp = np.load(\"../real_nvp_results_h3.npz\")\n",
    "log_prob_x = temp[\"log_prob_x\"]\n",
    "ind = temp[\"ind\"]\n",
    "print(ind.shape)\n",
    "\n",
    "temp = np.load(\"../H3_spectra.npz\")\n",
    "teff = temp[\"teff\"][ind]\n",
    "logg = temp[\"logg\"][ind]\n",
    "feh = temp[\"feh\"][ind]\n",
    "\n",
    "\n",
    "#=====================================================================================\n",
    "# import packages\n",
    "import read_mist_models\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# initiate the plot\n",
    "fig = plt.figure(figsize=[12,9]);\n",
    "ax = fig.gca();\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(\"Teff [K]\", fontsize=30, labelpad=10);\n",
    "ax.set_ylabel(\"Log g\", fontsize=30, labelpad=10);\n",
    "\n",
    "# set range\n",
    "plt.xlim([3000,6500])\n",
    "plt.ylim([-0.5,5.])\n",
    "\n",
    "# invert axis\n",
    "plt.gca().invert_xaxis()\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# add padding\n",
    "ax.tick_params(axis='x', pad=10);\n",
    "\n",
    "# reduce number of ticks\n",
    "plt.locator_params(nbins=5)\n",
    "\n",
    "\n",
    "#=====================================================================================\n",
    "# plot results\n",
    "sc = plt.scatter(teff, logg, s=20, edgecolor=\"none\", cmap=plt.cm.get_cmap('jet'),\\\n",
    "                 c=log_prob_x, vmin=4000, vmax=6000, rasterized=True)\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar().set_label(label=r\"log prob\",size=30)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# read mist models\n",
    "iso = read_mist_models.ISO('../isochrones_MIST/' \\\n",
    "                           + 'MIST_v1.1_feh_m2.00_afe_p0.0_vvcrit0.4_full.iso')\n",
    "\n",
    "# extract information\n",
    "age_ind = iso.age_index(np.log10(7*10**9))\n",
    "EEP = iso.isos[age_ind]['EEP']\n",
    "choose = (EEP > 202)*(EEP < 707)\n",
    "Teff_iso = 10.**iso.isos[age_ind]['log_Teff']\n",
    "logg_iso = iso.isos[age_ind]['log_g']\n",
    "        \n",
    "# plot isochrone\n",
    "plt.plot(Teff_iso[choose], logg_iso[choose], color=\"black\", lw=2, ls=\"--\", label=\"[Fe/H] = -0.50\")\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# read mist models\n",
    "iso = read_mist_models.ISO('../isochrones_MIST/' \\\n",
    "                           + 'MIST_v1.1_feh_m1.00_afe_p0.0_vvcrit0.4_full.iso')\n",
    "     \n",
    "# extract information\n",
    "age_ind = iso.age_index(np.log10(7*10**9))\n",
    "EEP = iso.isos[age_ind]['EEP']\n",
    "choose = (EEP > 202)*(EEP < 707)\n",
    "Teff_iso = 10.**iso.isos[age_ind]['log_Teff']\n",
    "logg_iso = iso.isos[age_ind]['log_g']\n",
    "        \n",
    "# plot isochrone\n",
    "plt.plot(Teff_iso[choose], logg_iso[choose], color=\"black\", lw=2, label=\"[Fe/H] = 0.00\")\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# read mist models\n",
    "iso = read_mist_models.ISO('../isochrones_MIST/' \\\n",
    "                           + 'MIST_v1.1_feh_p0.00_afe_p0.0_vvcrit0.4_full.iso')\n",
    "\n",
    "# extract information\n",
    "age_ind = iso.age_index(np.log10(10*10**9))\n",
    "EEP = iso.isos[age_ind]['EEP']\n",
    "choose = (EEP > 202)*(EEP < 707)\n",
    "Teff_iso = 10.**iso.isos[age_ind]['log_Teff']\n",
    "logg_iso = iso.isos[age_ind]['log_g']\n",
    "        \n",
    "# plot isochrone\n",
    "plt.plot(Teff_iso[choose], logg_iso[choose], color=\"black\", lw=2, ls=\":\", label=\"[Fe/H] = 0.50\")\n",
    "\n",
    "\n",
    "#=====================================================================================\n",
    "# save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../Fig7.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check spectra with respect to probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore results\n",
    "temp = np.load(\"../real_nvp_results_h3.npz\")\n",
    "log_prob_x = temp[\"log_prob_x\"]\n",
    "ind = temp[\"ind\"]\n",
    "\n",
    "# restore data\n",
    "temp = np.load(\"../H3_spectra.npz\")\n",
    "flux_spectra = temp[\"flux_spectra\"][ind,:]\n",
    "err_array = temp[\"err_array\"][ind]\n",
    "rest_wave = temp[\"rest_wave\"][ind,:]\n",
    "teff = temp[\"teff\"][ind]\n",
    "logg = temp[\"logg\"][ind]\n",
    "H3_id = temp[\"H3_id\"][ind]\n",
    "h3_flag = temp[\"h3_flag\"][ind]\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "# define a uniform wavelength grid\n",
    "uniform_wave = np.linspace(5162,5290,flux_spectra.shape[1])\n",
    "\n",
    "# interpolate to the rest frame\n",
    "for i in range(flux_spectra.shape[0]):\n",
    "    if np.median(flux_spectra[i]) != 0:\n",
    "        f_flux_spec = interpolate.interp1d(rest_wave[i,:], flux_spectra[i,:])\n",
    "        flux_spectra[i,:] = f_flux_spec(uniform_wave)\n",
    "                     \n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "# normalize spectra\n",
    "y_tr = (flux_spectra.T/np.median(flux_spectra, axis=1)).T\n",
    "\n",
    "# exclude bad pixels\n",
    "y_tr[np.isnan(y_tr)] = 1.\n",
    "y_tr[y_tr < 0.] = 0.\n",
    "y_tr[y_tr > 2] = 2.\n",
    "print(y_tr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = plt.scatter(err_array, log_prob_x, s=20, edgecolor=\"none\", cmap=plt.cm.get_cmap('jet'),\\\n",
    "                 c=logg, vmin=0, vmax=4.5, rasterized=True)\n",
    "plt.colorbar().set_label(label=r\"log g\",size=30)\n",
    "plt.xlabel(\"SNR\")\n",
    "plt.ylabel(\"log prob\")\n",
    "plt.ylim([3000,7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(H3_id == \"166510846\"))\n",
    "print(H3_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by log probablity\n",
    "print(log_prob_x.shape, y_tr.shape)\n",
    "ind_sort = np.argsort(log_prob_x)[::-1]\n",
    "log_prob_x_sort = log_prob_x[ind_sort]\n",
    "y_tr_sort = y_tr[ind_sort,:]\n",
    "logg_sort = logg[ind_sort]\n",
    "teff_sort = teff[ind_sort]\n",
    "h3_flag_sort = h3_flag[ind_sort]\n",
    "H3_id_sort = H3_id[ind_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the plot\n",
    "fig = plt.figure(figsize=[15,4.5]);\n",
    "ax = fig.gca();\n",
    "\n",
    "plt.plot(uniform_wave, y_tr_sort[(h3_flag_sort == 0)*(teff_sort > 5000)][:5,:].T, color=cb2[3], lw=1.,\\\n",
    "         label=\"High Probablity\", alpha=0.5);\n",
    "plt.plot(uniform_wave, y_tr_sort[(h3_flag_sort == 0)*(teff_sort > 5000)][4,:].T, color=\"black\", lw=3.,\\\n",
    "         label=\"High Probablity\", alpha=0.5);\n",
    "\n",
    "#plt.plot(uniform_wave, y_tr_sort[(h3_flag_sort == 0)*(teff_sort > 5000)][:5,:].T, color=cb2[3], lw=1.,\\\n",
    "#         label=\"High Probablity\", alpha=0.5);\n",
    "#plt.plot(uniform_wave, y_tr_sort[h3_flag_sort != 0][-25:-20,:].T, color=cb2[0], lw=1.5,\\\n",
    "#         label=\"Low Probability\", alpha=0.5);\n",
    "plt.xlabel(\"Wavelength [A]\")\n",
    "plt.ylabel(\"Normalized flux\")\n",
    "\n",
    "print(H3_id_sort[(h3_flag_sort == 0)*(teff_sort > 5000)][4])\n",
    "print(h3_flag_sort[h3_flag_sort != 0][:5])\n",
    "print(teff_sort[h3_flag_sort != 0][:5])\n",
    "print(log_prob_x_sort[h3_flag_sort != 0][-20:-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore data\n",
    "temp = np.load(\"../H3_spectra.npz\")\n",
    "h3_flag = temp[\"h3_flag\"]\n",
    "flux_spectra = temp[\"flux_spectra\"]\n",
    "err_array = temp[\"err_array\"]\n",
    "H3_id = temp[\"H3_id\"]\n",
    "rest_wave = temp[\"rest_wave\"]\n",
    "\n",
    "ind_special = np.where(H3_id == \"164663827\")[0][0]\n",
    "\n",
    "print(err_array[ind_special])\n",
    "print(h3_flag[ind_special])\n",
    "plt.plot(rest_wave[ind_special,:], flux_spectra[ind_special,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emulating galaxy images.\n",
    "\n",
    "> Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the array\n",
    "arr = np.load(\"../DES_DR1.npy\")\n",
    "\n",
    "# permute the data\n",
    "rng = np.random.RandomState(seed=42)\n",
    "pidx = rng.permutation(len(arr))\n",
    "arr = arr[pidx]\n",
    "    \n",
    "# crop the image\n",
    "arr = arr[:,32:96,32:96,:]\n",
    "\n",
    "# scale data\n",
    "arr = np.clip(np.arcsinh(0.01*arr)+0.4,0,5)/5\n",
    "\n",
    "# further scale to make the color pop\n",
    "arr[:,:,:,0] = arr[:,:,:,0] * 1.5\n",
    "arr[:,:,:,1] = arr[:,:,:,1] * 1.2\n",
    "arr[:,:,:,2] = arr[:,:,:,2] * 1.1\n",
    "arr = np.clip(arr,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a channel of an image\n",
    "channel_choice = 2\n",
    "\n",
    "# choose an image\n",
    "image_choice = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Histogram of individual channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(arr[:,:,:,0].ravel(), alpha=0.5, bins=100);\n",
    "plt.hist(arr[:,:,:,1].ravel(), alpha=0.5, bins=100);\n",
    "plt.hist(arr[:,:,:,2].ravel(), alpha=0.5, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Show images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(arr[image_choice,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore results\n",
    "import imageio\n",
    "\n",
    "# choose a subset of images\n",
    "X = arr[:64]\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot the tiled results\n",
    "n_samples = X.shape[0]\n",
    "rows = int(np.sqrt(n_samples))\n",
    "while n_samples % rows != 0:\n",
    "    rows -= 1\n",
    "\n",
    "nh, nw = rows, int(n_samples/rows)\n",
    "\n",
    "h, w = X[0].shape[:2]\n",
    "img = np.zeros((h*nh, w*nw, 3))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# loop over all images\n",
    "for n, x in enumerate(X):\n",
    "    j = int(n/nw)\n",
    "    i = n%nw\n",
    "    x_temp = np.copy(x)\n",
    "    img[j*h:j*h+h, i*w:i*w+w, :] = x_temp\n",
    "\n",
    "# save images\n",
    "imageio.imwrite(\"Results.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training set\n",
    "arr = np.swapaxes(arr,3,1)\n",
    "np.save(\"../training_set_des.npy\", arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_err_array = []\n",
    "\n",
    "for i in range(30):\n",
    "    temp = np.load(\"../new_results_2D_random_times=10_8\" \\\n",
    "                   + \"_epoch=\" + str((i+1)*100-1) + \".npz\")\n",
    "    mse_err_array.append(temp[\"mse_err\"])\n",
    "\n",
    "plt.plot(mse_err_array)\n",
    "plt.ylim([0.0001,0.001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Restore 2D networks and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore results\n",
    "temp = np.load(\"../results_2D.npz\")\n",
    "data_np = temp[\"data_np\"]\n",
    "plt.hist(np.log(data_np).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore results\n",
    "import imageio\n",
    "\n",
    "# restore results\n",
    "temp = np.load(\"../samples_closest_16x16.npz\")\n",
    "samples_np = temp[\"samples_np\"][::100,:][:400]\n",
    "\n",
    "# temp = np.load(\"../results_2D_lr=1e-5_times=10_lowlow_rez_epoch=1199.npz\")\n",
    "# samples_np = temp[\"samples_np\"][::10][:100,:]\n",
    "\n",
    "# temp = np.load(\"../results_2D_random_lr=1e-5_times=10_epoch=1299.npz\")\n",
    "# samples_np = temp[\"samples_np\"][:100,:]\n",
    "\n",
    "# swap channel axis\n",
    "X = np.swapaxes(samples_np,3,1)\n",
    "X = np.clip(X,0.1,1.)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot the tiled results\n",
    "n_samples = X.shape[0]\n",
    "rows = int(np.sqrt(n_samples))\n",
    "while n_samples % rows != 0:\n",
    "    rows -= 1\n",
    "\n",
    "nh, nw = rows, int(n_samples/rows)\n",
    "\n",
    "h, w = X[0].shape[:2]\n",
    "img = np.zeros((h*nh, w*nw, 3))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# loop over all images\n",
    "for n, x in enumerate(X):\n",
    "    j = int(n/nw)\n",
    "    i = n%nw\n",
    "    x_temp = np.copy(x)\n",
    "    img[j*h:j*h+h, i*w:i*w+w, :] = x_temp\n",
    "\n",
    "# save images\n",
    "imageio.imwrite(\"../Results_2D_mock.png\", img)\n",
    "\n",
    "\n",
    "#==============================================================================\n",
    "# restore results\n",
    "import imageio\n",
    "\n",
    "# restore results\n",
    "temp = np.load(\"../results_2D_8x8_low_rez_times=10.npz\")\n",
    "data_np = temp[\"data_np\"][::10,:][:100,:]\n",
    "\n",
    "# # restore results\n",
    "# temp = np.load(\"../results_2D_conditional_times3_best.npz\")\n",
    "# data_np = temp[\"data_np\"][::10,:][:100,:]\n",
    "# data_conv = np.empty((data_np.shape[0],)+(1,16,16))\n",
    "# for i in range(data_np.shape[0]):\n",
    "#     for j in range(16):\n",
    "#         for k in range(16):\n",
    "#             data_conv[i,:,j,k] = np.mean(data_np[i,0,j*4:(j+1)*4,k*4:(k+1)*4])\n",
    "# data_np = np.copy(data_conv)\n",
    "# print(data_np.reshape(data_np.shape[0],np.prod(data_np.shape[1:]),1,1).shape)\n",
    "\n",
    "# swap channel axis\n",
    "X = np.swapaxes(data_np,3,1)\n",
    "X = np.clip(X,0.1,1.)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot the tiled results\n",
    "n_samples = X.shape[0]\n",
    "rows = int(np.sqrt(n_samples))\n",
    "\n",
    "while n_samples % rows != 0:\n",
    "    rows -= 1\n",
    "\n",
    "nh, nw = rows, int(n_samples/rows)\n",
    "\n",
    "h, w = X[0].shape[:2]\n",
    "img = np.zeros((h*nh, w*nw, 3))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# loop over all images\n",
    "for n, x in enumerate(X):\n",
    "    j = int(n/nw)\n",
    "    i = n%nw\n",
    "    x_temp = np.copy(x)\n",
    "    img[j*h:j*h+h, i*w:i*w+w, :] = x_temp\n",
    "\n",
    "# save images\n",
    "imageio.imwrite(\"../Results_2D_real.png\", img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot variance sampling from residual latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore results\n",
    "#temp = np.load(\"../samples_closest_8x8.npz\")\n",
    "temp = np.load(\"../samples_closest_16x16.npz\")\n",
    "ind = 6\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "samples_np = np.mean(temp[\"samples_np\"][ind*100:(ind+1)*100,:], axis=0)\n",
    "plt.imshow(samples_np[0,:,:], vmin=0, vmax=1., cmap=\"Greys_r\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "samples_np = np.std(temp[\"samples_np\"][ind*100:(ind+1)*100,:], axis=0)\n",
    "plt.imshow(samples_np[0,:,:], vmin=0, vmax=0.1, cmap=\"Greys_r\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Restore 3D networks and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore results\n",
    "import imageio\n",
    "\n",
    "# restore results\n",
    "temp = np.load(\"../results_3D.npz\")\n",
    "samples_np = temp[\"samples_np\"][0,0,:,:,:]\n",
    "data_np = temp[\"data_np\"][0,0,:,:,:]\n",
    "\n",
    "# set range\n",
    "X = np.clip(samples_np,5.,10.)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot the tiled results\n",
    "n_samples = X.shape[0]\n",
    "rows = int(np.sqrt(n_samples))\n",
    "while n_samples % rows != 0:\n",
    "    rows -= 1\n",
    "\n",
    "nh, nw = rows, int(n_samples/rows)\n",
    "\n",
    "h, w = X[0].shape[:2]\n",
    "img = np.zeros((h*nh, w*nw))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# loop over all images\n",
    "for n, x in enumerate(X):\n",
    "    j = int(n/nw)\n",
    "    i = n%nw\n",
    "    x_temp = np.copy(x)\n",
    "    img[j*h:j*h+h, i*w:i*w+w] = x_temp\n",
    "\n",
    "# save images\n",
    "imageio.imwrite(\"../Results_3D_mock.png\", img)\n",
    "\n",
    "\n",
    "#==============================================================================\n",
    "# restore results\n",
    "import imageio\n",
    "\n",
    "# restore results\n",
    "temp = np.load(\"../results_3D.npz\")\n",
    "samples_np = temp[\"samples_np\"][0,0,:,:,:]\n",
    "data_np = temp[\"data_np\"][0,0,:,:,:]\n",
    "\n",
    "# set range\n",
    "X = np.clip(data_np,5.,10.)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# plot the tiled results\n",
    "n_samples = X.shape[0]\n",
    "rows = int(np.sqrt(n_samples))\n",
    "\n",
    "while n_samples % rows != 0:\n",
    "    rows -= 1\n",
    "\n",
    "nh, nw = rows, int(n_samples/rows)\n",
    "\n",
    "h, w = X[0].shape[:2]\n",
    "img = np.zeros((h*nh, w*nw))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# loop over all images\n",
    "for n, x in enumerate(X):\n",
    "    j = int(n/nw)\n",
    "    i = n%nw\n",
    "    x_temp = np.copy(x)\n",
    "    img[j*h:j*h+h, i*w:i*w+w] = x_temp\n",
    "\n",
    "# save images\n",
    "imageio.imwrite(\"../Results_3D_real.png\", img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(samples_np[10,0,slice,:,:], vmin=5, vmax=10, cmap=\"Greys\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples_np.shape)\n",
    "print(data_np.shape)\n",
    "plt.hist(samples_np.flatten(), bins=100);\n",
    "plt.hist(data_np.flatten(), bins=100, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate Zeldovich Approximation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore data\n",
    "temp = np.load(\"../Zeldovich_Approximation.npz\")\n",
    "sim_z0 = temp[\"sim_z0\"]\n",
    "sim_z0 = sim_z0.reshape(sim_z0.shape[0]*sim_z0.shape[1],1,sim_z0.shape[2],sim_z0.shape[3])\n",
    "sim_z0 = sim_z0[:,:,::2,::2][:,:,2:-2,2:-2]\n",
    "print(sim_z0.shape)\n",
    "sim_z50 = temp[\"sim_z50\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate NN structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "# define network\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "class DeeperConvImplicitModel(torch.nn.Module):\n",
    "    def __init__(self, z_dim, init_weight_factor = 1.):\n",
    "        super(DeeperConvImplicitModel, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.init_weight_factor = init_weight_factor\n",
    "\n",
    "        layers = [View((-1,z_dim,1,1))]\n",
    "\n",
    "        for i in range(4):\n",
    "\n",
    "            for j in range(5):\n",
    "\n",
    "                if i == 0 and j == 0:\n",
    "                    layers.append(torch.nn.ConvTranspose2d(z_dim, 512, 4, stride=1, padding=0))\n",
    "                    layers.append(torch.nn.BatchNorm2d(512, momentum=0.001, affine=False))\n",
    "                    layers.append(torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "                else:\n",
    "                    layers.append(torch.nn.Conv2d(512, 512, 5, stride=1, padding=2))\n",
    "                    layers.append(torch.nn.BatchNorm2d(512, momentum=0.001, affine=False))\n",
    "                    layers.append(torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "            if i < 3:\n",
    "                layers.append(torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners = False))\n",
    "            else:\n",
    "                layers.append(torch.nn.Conv2d(512, 3, 5, stride=1, padding=2))\n",
    "                layers.append(torch.nn.Sigmoid())\n",
    "\n",
    "        self.model = torch.nn.Sequential(*layers)\n",
    "        self.add_module(\"model\", self.model)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "    \n",
    "#----------------------------------------------------------------------------------------\n",
    "class IMLE():\n",
    "    def __init__(self, z_dim):\n",
    "        self.z_dim = z_dim\n",
    "        self.model = DeeperConvImplicitModel(z_dim)\n",
    "        \n",
    "    \n",
    "#========================================================================================\n",
    "# initate model\n",
    "z_dim = 64\n",
    "batch_size = 2        \n",
    "imle = IMLE(z_dim)\n",
    "\n",
    "# load previous model\n",
    "state_dict = torch.load(\"../checkpoint_single_channel_init_later.pth.tar\",\\\n",
    "                        map_location=torch.device('cpu'))\n",
    "imle.model.load_state_dict(state_dict)\n",
    "\n",
    "# test output\n",
    "z = torch.randn(batch_size, z_dim)\n",
    "print(imle(z).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"../training_set_des.npy\")[::100,0:1,:,:]\n",
    "print(train_data.shape)\n",
    "\n",
    "plt.hist(train_data.flatten(), bins=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustrate GAN / IMLE \n",
    "\n",
    "> Mode dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate plot\n",
    "fig = plt.figure(figsize=[10.,8.])\n",
    "ax = fig.gca();\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel(\"Image Space\", labelpad=20, fontsize=30);\n",
    "ax.set_ylabel(\"p ( Image )\", labelpad=20, fontsize=30);\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "from scipy.stats import norm\n",
    "x = np.linspace(-7.5, -2.5, 1000)\n",
    "plt.fill_between(x, np.zeros(x.size), 0.3*norm.pdf(x+5), alpha=0.5, color=cb2[1])\n",
    "\n",
    "x = np.linspace(-10, 5, 1000)\n",
    "plt.plot(x, norm.pdf(x) + 0.3*norm.pdf(x+5), 'k', lw=3)\n",
    "\n",
    "# save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../Mode_Collapse_2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Illustrate GAN unstable training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate result array\n",
    "array_x = np.zeros(500)\n",
    "array_y = np.zeros(500)\n",
    "array_x[0] = 1.\n",
    "array_y[0] = 0.\n",
    "\n",
    "# loop over all time step\n",
    "eta = 0.05\n",
    "counter = 1\n",
    "while counter < array_x.size - 1:\n",
    "    # min x\n",
    "    # x_new = x_old - eta*df/dx\n",
    "    array_x[counter] = array_x[counter-1] - eta*array_y[counter-1]\n",
    "    array_y[counter] = array_y[counter-1]\n",
    "    counter +=1 \n",
    "    \n",
    "    # max y\n",
    "    # y_new = y_old + eta*df/dy\n",
    "    array_x[counter] = array_x[counter-1]\n",
    "    array_y[counter] = array_y[counter-1] + eta*array_x[counter-1]\n",
    "    counter +=1 \n",
    "\n",
    "array_x = array_x[:-1]\n",
    "array_y = array_y[:-1]\n",
    "x = np.linspace(-1,1,100)\n",
    "plt.plot(x, np.sqrt(1.-x**2), color=\"white\")\n",
    "plt.scatter(array_x[:-1], array_y[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import interpolate\n",
    "from scipy.stats import norm\n",
    "import scipy.optimize as op\n",
    "\n",
    "from astropy import units\n",
    "from astropy.io import fits\n",
    "\n",
    "#from galpy.potential import MWPotential2014 as pot\n",
    "#from galpy.actionAngle import actionAngleStaeckel\n",
    "#from galpy.actionAngle import estimateDeltaStaeckel\n",
    "#from galpy.orbit import Orbit\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from cycler import cycler\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define plot properties\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import rc\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def rgb(r,g,b):\n",
    "    return (float(r)/256.,float(g)/256.,float(b)/256.)\n",
    "\n",
    "cb2 = [rgb(31,120,180), rgb(255,127,0), rgb(51,160,44), rgb(227,26,28), \\\n",
    "       rgb(166,206,227), rgb(253,191,111), rgb(178,223,138), rgb(251,154,153),\\\n",
    "       rgb(220,220,220), rgb(150,150,150)]\n",
    "cb3 = [rgb(255,171,113)]\n",
    "\n",
    "rcParams['figure.figsize'] = (11,7.5)\n",
    "rcParams['figure.dpi'] = 300\n",
    "\n",
    "rcParams['lines.linewidth'] = 1\n",
    "\n",
    "rcParams['axes.prop_cycle'] = cycler('color', cb2)\n",
    "rcParams['axes.grid'] = False\n",
    "\n",
    "rcParams['patch.facecolor'] = cb2[0]\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "\n",
    "rcParams['font.family'] = 'Bitstream Vera Sans'\n",
    "rcParams['font.size'] = 25\n",
    "rcParams['font.weight'] = 300\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "# invert color\n",
    "rcParams['text.color'] = 'white'\n",
    "\n",
    "rcParams['axes.facecolor'] = 'black'\n",
    "rcParams['axes.edgecolor'] = 'white'\n",
    "rcParams['axes.labelcolor'] = 'white'\n",
    "\n",
    "rcParams['xtick.color'] = 'white'\n",
    "rcParams['ytick.color'] = 'white'\n",
    "rcParams['grid.color'] = 'white'\n",
    "\n",
    "rcParams['figure.facecolor'] = 'black'\n",
    "rcParams['figure.edgecolor'] = 'black'\n",
    "\n",
    "rcParams['savefig.facecolor'] = 'black'\n",
    "rcParams['savefig.edgecolor'] = 'black'\n",
    "\n",
    "rcParams.update({'figure.autolayout': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video\n",
    "# initiate plot  \n",
    "fig = plt.figure(figsize=[9,7.5]);\n",
    "ax = fig.gca();\n",
    "\n",
    "plt.xlim([-1.2,1.2])\n",
    "plt.ylim([-1.2,1.2])\n",
    "\n",
    "ax.set_xlabel(r\"x\", fontsize=30);\n",
    "ax.set_ylabel(r\"y\", fontsize=30);\n",
    "    \n",
    "# initiate evolutionary point\n",
    "scat = ax.scatter(array_x[0], array_y[0], s=1000, color=cb2[5], edgecolors='none')\n",
    "\n",
    "x = np.linspace(-1,1,100)\n",
    "ax.plot(x, np.sqrt(1.-x**2), color=\"white\", lw=2, ls=\"--\")\n",
    "ax.plot(x, -np.sqrt(1.-x**2), color=\"white\", lw=2, ls=\"--\")     \n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "# initialization function\n",
    "def init():\n",
    "    scat.set_offsets([array_x[0],array_y[0]])\n",
    "    return scat,\n",
    "\n",
    "# animation function, this is called sequentially\n",
    "def animate(i):\n",
    "    scat.set_offsets([array_x[i],array_y[i]])\n",
    "    return scat,\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=array_x.shape[0], interval=20, blit=True)\n",
    "\n",
    "# save the animation as an mp4\n",
    "anim.save('Unstable_GAN.mp4', fps=30,\\\n",
    "          extra_args=['-vcodec', 'libx264','-preset', 'slow', '-pix_fmt', 'yuv420p',\n",
    "                      '-profile:v', 'baseline', '-movflags', 'faststart'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Illustrate normalizing flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate plot\n",
    "fig = plt.figure(figsize=[10.,8.])\n",
    "ax = fig.gca();\n",
    "\n",
    "# axis labels\n",
    "# ax.set_xlabel(\"x\", labelpad=20, fontsize=30);\n",
    "# ax.set_ylabel(\"p(x)\", labelpad=20, fontsize=30);\n",
    "#ax.set_xlabel(\"z\", labelpad=20, fontsize=30);\n",
    "#ax.set_ylabel(\"p(z)\", labelpad=20, fontsize=30);\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# from scipy.stats import norm\n",
    "# x = np.linspace(-10, 5, 1000)\n",
    "# plt.fill_between(x,  norm.pdf(x) + 0.3*norm.pdf(x+6) + 0.5*norm.pdf(x+3) + 0.2*norm.pdf(x-3), alpha=0.5, color=cb2[1])\n",
    "# x = np.linspace(-10, 5, 1000)\n",
    "# plt.plot(x, norm.pdf(x) + 0.3*norm.pdf(x+6) + 0.5*norm.pdf(x+3) + 0.2*norm.pdf(x-3), 'k', lw=3)\n",
    "\n",
    "x = np.linspace(-10, 5, 1000)\n",
    "plt.fill_between(x,  norm.cdf(x) + 0.3*norm.cdf(x+6) + 0.5*norm.cdf(x+3) + 0.2*norm.cdf(x-3), alpha=0.5, color=cb2[1])\n",
    "x = np.linspace(-10, 5, 1000)\n",
    "plt.plot(x, norm.cdf(x) + 0.3*norm.cdf(x+6) + 0.5*norm.cdf(x+3) + 0.2*norm.cdf(x-3), 'k', lw=3)\n",
    "\n",
    "\n",
    "#from scipy.stats import norm\n",
    "#x = np.linspace(-5, 5, 1000)\n",
    "#plt.fill_between(x, norm.pdf(x), alpha=0.5, color=cb2[0])\n",
    "#x = np.linspace(-5, 5, 1000)\n",
    "#plt.plot(x, norm.pdf(x), 'k', lw=3)\n",
    "\n",
    "#x = np.linspace(-5, 5, 1000)\n",
    "#plt.fill_between(x, norm.cdf(x), alpha=0.5, color=cb2[0])\n",
    "#x = np.linspace(-5, 5, 1000)\n",
    "#plt.plot(x, norm.cdf(x), 'k', lw=3)\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../normalizing_flow_3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustrate images.\n",
    "\n",
    "> Showing diverse recoveries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initiate plot\n",
    "fig = plt.figure(figsize=[16.,16.])\n",
    "\n",
    "# restore results\n",
    "temp = np.load(\"../results_2D_16x16_low_rez_times=10.npz\")\n",
    "data_np = temp[\"data_np\"][::30][45][0]\n",
    "samples_np = temp[\"samples_np\"][::30][45][0]\n",
    "# data_np = temp[\"data_np\"][::30][1][0]\n",
    "# samples_np = temp[\"samples_np\"][::30][1][0]\n",
    "\n",
    "# make images\n",
    "ax = fig.add_subplot(223)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "plt.imshow(samples_np.T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "\n",
    "# make images\n",
    "ax = fig.add_subplot(221)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "plt.imshow(data_np.T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# restore results\n",
    "temp = np.load(\"../results_2D_16x16_low_rez_times=10.npz\")\n",
    "# data_np = temp[\"data_np\"][::30][61][0]\n",
    "# samples_np = temp[\"samples_np\"][::30][61][0]\n",
    "data_np = temp[\"data_np\"][::30][55][0]\n",
    "samples_np = temp[\"samples_np\"][::30][55][0]\n",
    "\n",
    "# make images\n",
    "ax = fig.add_subplot(224)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "plt.imshow(samples_np.T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "\n",
    "# make images\n",
    "ax = fig.add_subplot(222)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "plt.imshow(data_np.T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# save figure\n",
    "plt.tight_layout(w_pad=500, h_pad=500)\n",
    "plt.savefig(\"../IMLE_Reconstruction_2.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Transitioning one galaxy to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert color\n",
    "rcParams['text.color'] = 'white'\n",
    "\n",
    "rcParams['axes.facecolor'] = 'black'\n",
    "rcParams['axes.edgecolor'] = 'white'\n",
    "rcParams['axes.labelcolor'] = 'white'\n",
    "\n",
    "rcParams['xtick.color'] = 'white'\n",
    "rcParams['ytick.color'] = 'white'\n",
    "rcParams['grid.color'] = 'white'\n",
    "\n",
    "rcParams['figure.facecolor'] = 'black'\n",
    "rcParams['figure.edgecolor'] = 'black'\n",
    "\n",
    "rcParams['savefig.facecolor'] = 'black'\n",
    "rcParams['savefig.edgecolor'] = 'black'\n",
    "\n",
    "rcParams['font.size'] = 30\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "#=======================================================================================\n",
    "# restore all snapshots\n",
    "temp = np.load(\"../samples_closest_video_transition.npz\")\n",
    "samples_np = temp[\"samples_np\"]\n",
    "snapshots = [samples_np[i][0].T for i in range(samples_np.shape[0])]\n",
    "\n",
    "\n",
    "#=======================================================================================\n",
    "# initiate the plot\n",
    "fig = plt.figure(figsize=[8,8]);\n",
    "ax = fig.gca()\n",
    "\n",
    "matplotlib.rcParams['axes.linewidth'] = 1.\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "# initiate\n",
    "a = snapshots[0]\n",
    "im = plt.imshow(a, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "# animate\n",
    "def animate_func(i):\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    im.set_array(snapshots[i])\n",
    "    return [im]\n",
    "\n",
    "fps = 200\n",
    "anim = animation.FuncAnimation(fig, animate_func, frames = len(snapshots)-1,\n",
    "                               interval = 1000/fps, # in ms\n",
    "                              )\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "# save video\n",
    "anim.save('../IMLE_Video_Galaxy_Transition.mp4', fps=fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate plot\n",
    "fig = plt.figure(figsize=[8.,8.])\n",
    "ax = fig.gca()\n",
    "\n",
    "# restore results\n",
    "# restore all snapshots\n",
    "temp = np.load(\"../samples_closest_video_transition.npz\")\n",
    "samples_np = temp[\"samples_np\"]\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "plt.imshow(samples_np[-1][0].T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "\n",
    "# save figure\n",
    "plt.tight_layout(w_pad=500, h_pad=500)\n",
    "plt.savefig(\"../IMLE_Reconstruction_4.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Showing inference uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate plot\n",
    "fig = plt.figure(figsize=[16.,16.])\n",
    "\n",
    "# restore results\n",
    "temp = np.load(\"../samples_closest_4x4.npz\")\n",
    "ind = 7\n",
    "samples_mean = np.mean(temp[\"samples_np\"][ind*100:(ind+1)*100,:], axis=0)[0]\n",
    "samples_std = np.std(temp[\"samples_np\"][ind*100:(ind+1)*100,:], axis=0)[0]\n",
    "\n",
    "# truth\n",
    "data_np = temp[\"data_np\"][ind][0]\n",
    "\n",
    "pix_choice = 4\n",
    "data_conv = np.empty((pix_choice,pix_choice))\n",
    "avg_choice = 64//pix_choice\n",
    "\n",
    "for j in range(pix_choice):\n",
    "    for k in range(pix_choice):\n",
    "        data_conv[j,k] = np.mean(data_np[j*avg_choice:(j+1)*avg_choice,\\\n",
    "                                         k*avg_choice:(k+1)*avg_choice])\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "# make images\n",
    "ax = fig.add_subplot(221)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "im = ax.imshow(data_np.T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "\n",
    "ax = fig.add_subplot(222)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "im = ax.imshow(data_conv.T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "\n",
    "ax = fig.add_subplot(223)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "im = ax.imshow(samples_mean.T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "fig.colorbar(im, orientation=\"horizontal\", pad=0.02, fraction=0.047)\n",
    "\n",
    "# make images\n",
    "ax = fig.add_subplot(224)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "im = ax.imshow(samples_std.T, cmap=\"Greys\", interpolation='bicubic', vmin=0, vmax=0.2)\n",
    "fig.colorbar(im, orientation=\"horizontal\", pad=0.02, fraction=0.047)\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# save figure\n",
    "plt.tight_layout(w_pad=500, h_pad=500)\n",
    "plt.savefig(\"../IMLE_Uncertainty_4x4.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate plot\n",
    "fig = plt.figure(figsize=[16.,16.])\n",
    "\n",
    "# restore results\n",
    "temp = np.load(\"../samples_closest_inner_4x4.npz\")\n",
    "ind = 4\n",
    "samples_mean = np.mean(temp[\"samples_np\"][ind*100:(ind+1)*100,:], axis=0)[0]\n",
    "samples_std = np.std(temp[\"samples_np\"][ind*100:(ind+1)*100,:], axis=0)[0]\n",
    "\n",
    "# truth\n",
    "data_np = temp[\"data_np\"][ind][0]\n",
    "\n",
    "pix_choice = 4\n",
    "data_conv = np.zeros((64,64))\n",
    "data_conv[32-pix_choice:32+pix_choice, 32-pix_choice:32+pix_choice] = \\\n",
    "    data_np[32-pix_choice:32+pix_choice, 32-pix_choice:32+pix_choice]\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "# make images\n",
    "ax = fig.add_subplot(221)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "im = ax.imshow(data_np.T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "\n",
    "ax = fig.add_subplot(222)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "im = ax.imshow(data_conv.T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "\n",
    "ax = fig.add_subplot(223)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "im = ax.imshow(samples_mean.T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "fig.colorbar(im, orientation=\"horizontal\", pad=0.02, fraction=0.047)\n",
    "\n",
    "# make images\n",
    "ax = fig.add_subplot(224)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "im = ax.imshow(samples_std.T, cmap=\"Greys\", interpolation='bicubic', vmin=0, vmax=0.05)\n",
    "fig.colorbar(im, orientation=\"horizontal\", pad=0.02, fraction=0.047)\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# save figure\n",
    "plt.tight_layout(w_pad=500, h_pad=500)\n",
    "plt.savefig(\"../IMLE_Uncertainty_4x4.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Scattering recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate plot\n",
    "fig = plt.figure(figsize=[16.,16.])\n",
    "\n",
    "# restore results\n",
    "temp = np.load(\"../samples_closest_0x0.npz\")\n",
    "ind = 7\n",
    "samples_mean = np.mean(temp[\"samples_np\"][ind*100:(ind+1)*100,:], axis=0)[0]\n",
    "samples_std = np.std(temp[\"samples_np\"][ind*100:(ind+1)*100,:], axis=0)[0]\n",
    "\n",
    "# truth\n",
    "data_np = temp[\"data_np\"][ind][0]\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "# make images\n",
    "ax = fig.add_subplot(221)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "im = ax.imshow(data_np.T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "\n",
    "ax = fig.add_subplot(223)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "im = ax.imshow(samples_mean.T, cmap=\"Greys_r\", interpolation='bicubic', vmin=0, vmax=1.)\n",
    "fig.colorbar(im, orientation=\"horizontal\", pad=0.02, fraction=0.047)\n",
    "\n",
    "# make images\n",
    "ax = fig.add_subplot(224)\n",
    "plt.setp(ax.get_xticklabels(), visible=False)\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "plt.xlabel(\" \")\n",
    "plt.ylabel(\" \")\n",
    "im = ax.imshow(samples_std.T, cmap=\"Greys\", interpolation='bicubic', vmin=0, vmax=0.05)\n",
    "fig.colorbar(im, orientation=\"horizontal\", pad=0.02, fraction=0.047)\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "# save figure\n",
    "plt.tight_layout(w_pad=500, h_pad=500)\n",
    "plt.savefig(\"../IMLE_Uncertainty_4x4.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore scattering coefficients\n",
    "train_Sx = np.load(\"Sx_Illustris_Images_J=6_L=2.npy\")[::30,:,None,None]\n",
    "print(train_Sx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
